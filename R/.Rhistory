xlim(c(-intpd+2, npds-intpd-2)) +
facet_grid( scenario ~ effect.type ) +
theme_bw() + theme(legend.position='top')
print(patt)
View(dfx.att)
dfx.att[which(dfx.att$t0==-77),]
#######################################################
## SIMULATION RUNS
#######################################################
n <- 200    ## Number of firms
npds <- 150  ## Number of periods
intpd <- round( npds / 4 )
## dynamic treatment effect types (shapes)
effect.types <- c('constant','quadratic','geometric')
# Specify simulation parameters
simlist <- list(
`1.no.perf.no.gro`=list(
b4=0, ## b4 = past performance spillover (or persistence)
b5=0  ## b5 = growth rate
),
`2.no.perf.lo.gro`=list(
b4=0, b5=.02
),
`3.mi.perf.lo.gro`=list(
b4=3/4, b5=.02
)
)
## --- TEST ---
# simlist <- list(
#   no.perf.no.gro=list(
#       b4=0, ## b4 = past performance spillover (or persistence)
#       b5=0  ## b5 = growth rate
#     )
# )
##-------------
## Run Simulation List
sim.id <- round(as.numeric(Sys.time()))
for (i in 1:length(simlist)) {
key <- names(simlist)[i]
sim <- simlist[[key]]
cat(sprintf('\nScenario label: %s\n\n', key))
# cat(str(simlist[[key]]))
simlist[[key]]$sim <- runSimInternalInterventionEffectComparison(
n = n, ## NUMBER OF FIRMS
npds = npds, ## NUMBER OF PERIODS
intpd = intpd, ## intervention after first section
ystart = 0,
effect.types = effect.types,
# benchmark.type = 'self', ## 'all', 'self'
treat.rule = 'below.benchmark',
treat.threshold = 0.02,  # 0.015
sim.id = sim.id, ## defaults to timestamp
##
b4 = sim$b4, ## past performance
b5 = sim$b5, ## growth (linear function of time t)
## Dynamic treatment effect function parameters
w0 = 1.7,  ## constant
w1 = 0.18,  ## linear
w2 = -0.005,  ## quadratic
## TODO: CHECK w2.shift SENSITIVITY - this shifts quadratic curve several periods to the right so that treatment effect increases slowly
w2.shift = -round(.2*intpd),  ## optimal value here is likely a function of the combination of treatment effect function parameters
## Plotting
plot.show=TRUE,
plot.save=TRUE
)
}
##--------------------------------------
##  COMBINED PLOT FACET GRID
##   - Simulation Scenario by dynamic treatment effect shape
##--------------------------------------
dfx.t0.summary <- data.frame(stringsAsFactors = F)
dfx.att <- data.frame(stringsAsFactors = F)
for (i in 1:length(simlist)) {
dfx.sim.i <- simlist[[i]]$sim$df.t0.summary
dfx.sim.i$scenario <- names(simlist)[i]
dfx.t0.summary <- rbind(dfx.t0.summary,  dfx.sim.i)
##
dfx.att.i <- simlist[[i]]$sim$df.att
dfx.att.i$scenario <- names(simlist)[i]
dfx.att <- rbind(dfx.att,  dfx.att.i)
}
pall <- ggplot(dfx.t0.summary, aes(x=t0, y=med, color=group)) +
geom_ribbon(aes(ymin=cl,ymax=cu,fill=group), alpha=.15, size=.01, lty=1) +
geom_line(size=1.2) +
# geom_point(aes(x=t, y=min),pch=1,alpha=.3) + geom_point(aes(x=t,y=max),pch=1,alpha=.3) +
geom_hline(yintercept=0) + geom_vline(xintercept=0, lty=2) +
ylab('Y') +
xlim(c(-intpd+2, npds-intpd-2)) +
facet_grid( scenario ~ effect.type ) +
theme_bw() + theme(legend.position='top')
print(pall)
## Average Treatment Effect on the Treated (empirical difference between treated and controlled by day from simulation)
patt <- ggplot(dfx.att, aes(x=t0, y=y.att)) +
# geom_ribbon(aes(ymin=cl,ymax=cu,fill=group), alpha=.15, size=.01, lty=1) +
geom_line(size=1.2) +
# geom_point(aes(x=t, y=min),pch=1,alpha=.3) + geom_point(aes(x=t,y=max),pch=1,alpha=.3) +
geom_hline(yintercept=0) + geom_vline(xintercept=0, lty=2) +
ylab('ATT') +
xlim(c(-intpd+2, npds-intpd-2)) +
facet_grid( scenario ~ effect.type ) +
theme_bw() + theme(legend.position='top')
print(patt)
#######################################################
## SIMULATION RUNS
#######################################################
n <- 300    ## Number of firms
npds <- 100  ## Number of periods
intpd <- round( npds / 4 )
## dynamic treatment effect types (shapes)
effect.types <- c('constant','quadratic','geometric')
# Specify simulation parameters
simlist <- list(
`1.no.perf.no.gro`=list(
b4=0, ## b4 = past performance spillover (or persistence)
b5=0  ## b5 = growth rate
),
`2.no.perf.lo.gro`=list(
b4=0, b5=.02
),
`3.mi.perf.lo.gro`=list(
b4=3/4, b5=.02
)
)
## --- TEST ---
# simlist <- list(
#   no.perf.no.gro=list(
#       b4=0, ## b4 = past performance spillover (or persistence)
#       b5=0  ## b5 = growth rate
#     )
# )
##-------------
## Run Simulation List
sim.id <- round(as.numeric(Sys.time()))
for (i in 1:length(simlist)) {
key <- names(simlist)[i]
sim <- simlist[[key]]
cat(sprintf('\nScenario label: %s\n\n', key))
# cat(str(simlist[[key]]))
simlist[[key]]$sim <- runSimInternalInterventionEffectComparison(
n = n, ## NUMBER OF FIRMS
npds = npds, ## NUMBER OF PERIODS
intpd = intpd, ## intervention after first section
ystart = 0,
effect.types = effect.types,
# benchmark.type = 'self', ## 'all', 'self'
treat.rule = 'below.benchmark',
treat.threshold = 0.02,  # 0.015
sim.id = sim.id, ## defaults to timestamp
##
b4 = sim$b4, ## past performance
b5 = sim$b5, ## growth (linear function of time t)
## Dynamic treatment effect function parameters
w0 = 1.7,  ## constant
w1 = 0.18,  ## linear
w2 = -0.005,  ## quadratic
## TODO: CHECK w2.shift SENSITIVITY - this shifts quadratic curve several periods to the right so that treatment effect increases slowly
w2.shift = -round(.2*intpd),  ## optimal value here is likely a function of the combination of treatment effect function parameters
## Plotting
plot.show=TRUE,
plot.save=TRUE
)
}
##--------------------------------------
##  COMBINED PLOT FACET GRID
##   - Simulation Scenario by dynamic treatment effect shape
##--------------------------------------
dfx.t0.summary <- data.frame(stringsAsFactors = F)
dfx.att <- data.frame(stringsAsFactors = F)
for (i in 1:length(simlist)) {
dfx.sim.i <- simlist[[i]]$sim$df.t0.summary
dfx.sim.i$scenario <- names(simlist)[i]
dfx.t0.summary <- rbind(dfx.t0.summary,  dfx.sim.i)
##
dfx.att.i <- simlist[[i]]$sim$df.att
dfx.att.i$scenario <- names(simlist)[i]
dfx.att <- rbind(dfx.att,  dfx.att.i)
}
pall <- ggplot(dfx.t0.summary, aes(x=t0, y=med, color=group)) +
geom_ribbon(aes(ymin=cl,ymax=cu,fill=group), alpha=.15, size=.01, lty=1) +
geom_line(size=1.2) +
# geom_point(aes(x=t, y=min),pch=1,alpha=.3) + geom_point(aes(x=t,y=max),pch=1,alpha=.3) +
geom_hline(yintercept=0) + geom_vline(xintercept=0, lty=2) +
ylab('Y') +
xlim(c(-intpd+2, npds-intpd-2)) +
facet_grid( scenario ~ effect.type ) +
theme_bw() + theme(legend.position='top')
print(pall)
## Average Treatment Effect on the Treated (empirical difference between treated and controlled by day from simulation)
patt <- ggplot(dfx.att, aes(x=t0, y=y.att)) +
# geom_ribbon(aes(ymin=cl,ymax=cu,fill=group), alpha=.15, size=.01, lty=1) +
geom_line(size=1.2) +
# geom_point(aes(x=t, y=min),pch=1,alpha=.3) + geom_point(aes(x=t,y=max),pch=1,alpha=.3) +
geom_hline(yintercept=0) + geom_vline(xintercept=0, lty=2) +
ylab('ATT') +
xlim(c(-intpd+2, npds-intpd-2)) +
facet_grid( scenario ~ effect.type ) +
theme_bw() + theme(legend.position='top')
print(patt)
library(did)
sp <- reset.sim()
set.seed(1814)
time.periods <- 4
## cannot reproduce results at
## https://cran.r-project.org/web/packages/did/vignettes/did-basics.html
## sp$te.e <- 1:time.periods
sp$te.e <- (1:time.periods) - 1
dta <- build_sim_dataset(sp)
nrow(dta)
head(dta)
example_attgt <- att_gt(yname = "Y",
tname = "period",
idname = "id",
gname = "G",
xformla = ~X,
data = dta
)
summary(example_attgt)
ggdid(example_attgt)
agg.simple <- aggte(example_attgt, type='simple')
summary(agg.simple)
## DYNAMIC EFFECTS AND EVENT STUDIES
agg.es <- aggte(example_attgt, type = "dynamic")
summary(agg.es)
ggdid(agg.es)
## Group-Specific Effects
agg.gs <- aggte(example_attgt, type = "group")
summary(agg.gs)
ggdid(agg.gs)
## Calendar Time Effects
agg.ct <- aggte(example_attgt, type = "calendar")
summary(agg.ct)
ggdid(agg.ct)
head(dta)
library(did)
library(bsts)
library(CausalImpact)
getwd()
library(did)
library(bsts)
library(CausalImpact)
work_dir <- 'C:\\Users\\sdr8y\\OneDrive - University of Missouri\\Research\\BSTS'
dat <- read.csv(file.path(work_dir,'cconma_purchase_data.csv'))
library(tibble)
dat <- as_tibble(dat)
dat
View(dat)
library(lubridate)
dat$follower_reg_date[1]
ymd(dat$follower_reg_date)
dat$follower_reg_date <- ymd(dat$follower_reg_date)
max(dat$follower_reg_date) - min(dat$follower_reg_date)
max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)
## weekly batches
nbatch <- (max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 52 ## weeks
nbatch
## weekly batches
nbatch <- as.numeric( (max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 52 ) ## weeks
nbatch
## weekly batches
nbatch <- ceiling( (max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 52 ) ## weeks
nbatch
## weekly batches
nbatch <- ceiling(as.numeric (max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 52 )) ## weeks
## weekly batches
nbatch <- ceiling(as.numeric( max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T) / 52 )) ## weeks
## weekly batches
nbatch <- ceiling(as.numeric( (max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 52 )) ## weeks
nbatch
max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)
(max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 7
## weekly batches
nbatch <- ceiling(as.numeric(
(max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 7
)) ## weeks
nbatch
nbatch * 7
dat$follower_reg_week <- week(dat$follower_reg_date)
unique(dat$follower_reg_week)
dat$yr
paste(dat$yr, dat$follower_reg_week, collapse = '_')
paste(c('a','b'),c(2010,2011), collapse="_")
. =  apply(data.frame(yr=dat$yr,w=dat$follower_reg_week),1,function(x)paste(x,collapse = '_'))
head(.)
head(., 200)
dat$pd_week <- apply(data.frame(yr=dat$yr,w=dat$follower_reg_week),1,function(x)paste(x,collapse = '_'))
pds <- sort(unique(dat$pd_week),decreasing = F)
pds
sprintf('%d_%02d',2019,1)
dat$pd_week <- apply(data.frame(yr=dat$yr,w=dat$follower_reg_week),1,function(x)sprintf('%s_%02d',x[1],x[2]))
class(dat$pd_week)
pds <- sort(unique(dat$pd_week),decreasing = F)
pds
dim(dat)
## DROP missing week rows (NAs)
dat <- dat[!is.na(dat$follower_reg_week),]
dat
npds <- length(pds)
work_dir <- 'C:\\Users\\sdr8y\\OneDrive - University of Missouri\\Research\\BSTS'
dat <- read.csv(file.path(work_dir,'cconma_purchase_data.csv'))
dat <- as_tibble(dat)
dat$follower_reg_date <- ymd(dat$follower_reg_date)
# ## weekly batches
# nbatch <- ceiling(as.numeric(
#   (max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 7
# )) ## weeks
dat$follower_reg_week <- week(dat$follower_reg_date)
## DROP missing week rows (NAs)
df <- dat[!is.na(dat$follower_reg_week),]
View(dat[is.na(dat$follower_reg_week),])
cohorts <- data.frame()
for (t in 1:length(npds)) {
pd <- pds[t]
x <- df[df$pd_week==pd,]
new <- x$mem_no[which( ! x$mem_no %in% cohorts$mem_no)]
cohorts <- rbind(cohorts, data.frame(mem_no=unique(new),pd=pd))
}
work_dir <- 'C:\\Users\\sdr8y\\OneDrive - University of Missouri\\Research\\BSTS'
dat <- read.csv(file.path(work_dir,'cconma_purchase_data.csv'))
dat <- as_tibble(dat)
dat$follower_reg_date <- ymd(dat$follower_reg_date)
# ## weekly batches
# nbatch <- ceiling(as.numeric(
#   (max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 7
# )) ## weeks
dat$follower_reg_week <- week(dat$follower_reg_date)
## DROP missing week rows (NAs)
df <- dat[!is.na(dat$follower_reg_week),]
df$pd_week <- apply(data.frame(yr=df$yr,w=df$follower_reg_week),1,function(x)sprintf('%s_%02d',x[1],x[2]))
pds <- sort(unique(df$pd_week),decreasing = F)
npds <- length(pds)
## Loop to create periods
cohorts <- data.frame()
for (t in 1:length(npds)) {
pd <- pds[t]
x <- df[df$pd_week==pd,]
new <- x$mem_no[which( ! x$mem_no %in% cohorts$mem_no)]
cohorts <- rbind(cohorts, data.frame(mem_no=unique(new),pd=pd))
}
View(cohorts)
## Loop to create periods
cohorts <- data.frame()
for (t in 1:length(npds)) {
pd <- pds[t]
x <- df[df$pd_week==pd,]
new <- unique(x$mem_no[which( ! x$mem_no %in% cohorts$mem_no)])
cohorts <- rbind(cohorts, data.frame(mem_no=new,pd=rep(pd,length(new))))
}
pds <- sort(unique(df$pd_week),decreasing = F)
## Loop to create periods
cohorts <- data.frame()
for (t in 1:length(pds)) {
pd <- pds[t]
x <- df[df$pd_week==pd,]
new <- unique(x$mem_no[which( ! x$mem_no %in% cohorts$mem_no)])
cohorts <- rbind(cohorts, data.frame(mem_no=new,pd=rep(pd,length(new))))
}
cohorts
dim(cohorts)
## Loop to create periods
cohorts <- data.frame()
df$pd_week_num <- NA
for (t in 1:length(pds)) {
pd <- pds[t]
x <- df[df$pd_week==pd,]
new <- unique(x$mem_no[which( ! x$mem_no %in% cohorts$mem_no)])
cohorts <- rbind(cohorts, data.frame(mem_no=new,pd=rep(pd,length(new))))
df$pd_week_num[which(df$pd_week==pd)] <- t
}
View(df)
library(tibble)
library(did)
library(bsts)
library(CausalImpact)
library(lubridate)
work_dir <- 'C:\\Users\\sdr8y\\OneDrive - University of Missouri\\Research\\BSTS'
dat <- read.csv(file.path(work_dir,'cconma_purchase_data.csv'))
dat <- as_tibble(dat)
dat$follower_reg_date <- ymd(dat$follower_reg_date)
# ## weekly batches
# nbatch <- ceiling(as.numeric(
#   (max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 7
# )) ## weeks
dat$follower_reg_week <- week(dat$follower_reg_date)
## DROP missing week rows (NAs)
df <- dat[!is.na(dat$follower_reg_week),]
range(dat$follower_reg_date)
range(dat$follower_reg_date, na.rm=T)
df$pd_week <- apply(data.frame(yr=df$yr,w=df$follower_reg_week),1,function(x)sprintf('%s_%02d',x[1],x[2]))
pds <- sort(unique(df$pd_week),decreasing = F)
## Loop to create periods
cohorts <- data.frame()
df$pd_week_num <- NA
t = 1
pd <- pds[t]
x <- df[df$pd_week==pd,]
new <- unique(x$mem_no[which( ! x$mem_no %in% cohorts$mem_no)])
cohorts <- rbind(cohorts, data.frame(mem_no=new,pd=rep(pd,length(new))))
df$pd_week_num[which(df$pd_week==pd)] <- t
x
View(x)
View(data.frame(yr=df$yr,w=df$follower_reg_week))
dat$follower_reg_week <- week(dat$follower_reg_date)
dat$follower_reg_year <- year(dat$follower_reg_date)
## DROP missing week rows (NAs)
df <- dat[!is.na(dat$follower_reg_week),]
df$pd_week <- apply(data.frame(yr=df$follower_reg_year,w=df$follower_reg_week),1,function(x)sprintf('%s_%02d',x[1],x[2]))
pds <- sort(unique(df$pd_week),decreasing = F)
pds
## Loop to create periods
cohorts <- data.frame()
df$pd_week_num <- NA
for (t in 1:length(pds)) {
pd <- pds[t]
x <- df[df$pd_week==pd,]
new <- unique(x$mem_no[which( ! x$mem_no %in% cohorts$mem_no)])
cohorts <- rbind(cohorts, data.frame(mem_no=new,pd=rep(pd,length(new))))
df$pd_week_num[which(df$pd_week==pd)] <- t
}
heaD9df
head(df)
View(df)
npds <- length(pds)
View(df)
df$cohort_pd_week <- apply(data.frame(yr=df$follower_reg_year,w=df$follower_reg_week),1,function(x)sprintf('%s_%02d',x[1],x[2]))
df$order_week <- week(df$order_date)
df$order_year <- year(df$order_date)
df$order_pd_week <- apply(data.frame(yr=df$order_year,w=df$order_week),1,function(x)sprintf('%s_%02d',x[1],x[2]))
library(tibble)
library(did)
library(bsts)
library(CausalImpact)
library(lubridate)
work_dir <- 'C:\\Users\\sdr8y\\OneDrive - University of Missouri\\Research\\BSTS'
dat <- read.csv(file.path(work_dir,'cconma_purchase_data.csv'))
dat <- as_tibble(dat)
dat$follower_reg_date <- ymd(dat$follower_reg_date)
# ## weekly batches
# nbatch <- ceiling(as.numeric(
#   (max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 7
# )) ## weeks
dat$follower_reg_week <- week(dat$follower_reg_date)
dat$follower_reg_year <- year(dat$follower_reg_date)
## DROP missing week rows (NAs)
df <- dat[!is.na(dat$follower_reg_week),]
df$cohort_pd_week <- apply(data.frame(yr=df$follower_reg_year,w=df$follower_reg_week),1,function(x)sprintf('%s_%02d',x[1],x[2]))
df$order_week <- week(df$order_date)
df$order_year <- year(df$order_date)
df$order_pd_week <- apply(data.frame(yr=df$order_year,w=df$order_week),1,function(x)sprintf('%s_%02d',x[1],x[2]))
pds.cohort <- sort(unique(df$cohort_pd_week), decreasing = F)
pds <- sort(unique(df$order_pd_week),decreasing = F)
npds <- length(pds)
## Loop to create periods
cohorts <- data.frame()
# df$cohort_pd_week_num <- NA
# df$cohort_pd_week_t0 <- NA
df$order_pd_week_num <- NA
df$order_pd_week_t0 <- NA
for (t in 1:npds) {
pd <- pds[t]
x <- df[df$cohort_pd_week==pd,]
new <- unique(x$mem_no[which( ! x$mem_no %in% cohorts$mem_no)])
cohorts <- rbind(cohorts, data.frame(mem_no=new,pd=rep(pd,length(new))))
idx <- which(df$cohort_pd_week==pd)
# df$cohort_pd_week_num[idx] <- t
# df$cohort_pd_week_t0[idx] <- t -
df$order_pd_week_num[idx] <- t
df$order_pd_week_t0[idx] <- t - df$cohort_pd_week_num[idx] + 1
}
dat <- read.csv(file.path(work_dir,'cconma_purchase_data.csv'))
dat <- as_tibble(dat)
dat$follower_reg_date <- ymd(dat$follower_reg_date)
# ## weekly batches
# nbatch <- ceiling(as.numeric(
#   (max(dat$follower_reg_date, na.rm=T) - min(dat$follower_reg_date, na.rm=T)) / 7
# )) ## weeks
dat$follower_reg_week <- week(dat$follower_reg_date)
dat$follower_reg_year <- year(dat$follower_reg_date)
## DROP missing week rows (NAs)
df <- dat[!is.na(dat$follower_reg_week),]
df$cohort_pd_week <- apply(data.frame(yr=df$follower_reg_year,w=df$follower_reg_week),1,function(x)sprintf('%s_%02d',x[1],x[2]))
df$order_week <- week(df$order_date)
df$order_year <- year(df$order_date)
df$order_pd_week <- apply(data.frame(yr=df$order_year,w=df$order_week),1,function(x)sprintf('%s_%02d',x[1],x[2]))
pds.cohort <- sort(unique(df$cohort_pd_week), decreasing = F)
pds <- sort(unique(df$order_pd_week),decreasing = F)
npds <- length(pds)
npds
## Loop to create periods
cohorts <- data.frame()
# df$cohort_pd_week_num <- NA
# df$cohort_pd_week_t0 <- NA
df$order_pd_week_num <- NA
df$order_pd_week_t0 <- NA
t =1
pd <- pds[t]
x <- df[df$cohort_pd_week==pd,]
new <- unique(x$mem_no[which( ! x$mem_no %in% cohorts$mem_no)])
cohorts <- rbind(cohorts, data.frame(mem_no=new,pd=rep(pd,length(new))))
idx <- which(df$cohort_pd_week==pd)
idx <- which(df$order_pd_week==pd)
pd
x
pd <- pds[t]
x <- df[df$order_pd_week==pd,]
new <- unique(x$mem_no[which( ! x$mem_no %in% cohorts$mem_no)])
dir_dat <- 'D:\\BSTS_external\\bsts_default_state_space'
files <- dir(dir_dat, pattern = '.rds')
files
getwd()
setwd('C:\\Users\\sdr8y\\OneDrive - University of Missouri\\Research\\BSTS\\R')
getwd()
dir()
