---
title: "A Bayesian Counterfactual Approach to Dynamic Causal Inference: R Code and Tutorial"
author: 
  - "Author 1^[Information redacted for review]"
  - "Author 2^[Information redacted for review]"
email: "<email redacted for review>"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document:
    keep_md: true
    toc: true
---

```{r initExclude, setup, message=FALSE, include=FALSE}
# output: pdf_document
rm(list=ls())
library(plyr)
library(dplyr)
library(tidyr)
library(tibble)
library(CausalImpact)
library(bsts)
library(did)
library(ggpubr)
library(cowplot)
library(coda)
library(Boom)
library(BoomSpikeSlab)
library(e1071)
library(forecast)  ## # library(sarima); library(qualV)
## reproducibility
rand.seed <- 134245 ## 9598677

set.seed(rand.seed)  

## Directories
dir_proj <- 'C:\\Users\\sdr8y\\OneDrive - University of Missouri\\Research\\BSTS'
dir_ext <- 'D:\\BSTS_external'
dir_rep <- file.path(dir_ext, 'bsts_did_replication_sensitivity')
dir_plot <- file.path(dir_proj, 'plots')
dir_r <- file.path(dir_proj,'R')
##  file prefix for saving images, writing outputs, etc.
prefix <- 'bsts-illus_vignette_'

## Load simulation functions - Actor index vectorized simulation
source(file.path(dir_r,'single_intervention_sim_vec.R')) 
## Setting up and adding state space components to state.space list
source(file.path(dir_r,'bsts_helper_functions.R')) 
## BSTS vs. DiD comparison and sensitivity analysis
source(file.path(dir_r,'bsts_did_comparison_functions.R')) 

## Knitr root dir - PDF rendering of notebook
knitr::opts_knit$set(root.dir = dir_proj)

## MAIN SIM SETTINGS
n <- 100  ## number of actors (i.e., number of time series)
npds <- 520
intpd <- round( npds * .6 )
effect.type <- 'quadratic' ##  c('constant','geometric','quadratic') 
bsts.ctrl.cats <- NA

##
sim.config <- list(
  ##--------Simulation settings--------------
  n = n,    ## Number of firms
  npds = npds,  ## Number of periods
  intpd = intpd, ## #intervention period = (5/6)'ths of the total periods 
  noise.level = 1.0, ## stdev of simulated noise terms
  prior.sd.scenario = 'sd.low', ## BSTS Prior SD scenario (high vs. low uncertainty in priors
  treat.rule = 'random', 
  treat.prob =  0.5,  ## ifelse(treat.rule=='random', 0.5, 1), 
  treat.threshold = 1, ## ifelse(treat.rule=='random', 1, 0.5),
  seasonality = TRUE,
  dgp.nseasons= 52,  ## ifelse(seasonality, dgp.nseasons, NA), 
  dgp.freq=  1, ##ifelse(seasonality, dgp.freq, NA),
  rand.seed = rand.seed,
  ## Dynamic treatment effect  (quadratic polynomial)
  w0 = 1.0,  ## constant
  w1 = 0.03, ## linear
  w2 = -0.00333 /sqrt(npds), ## quadratic
  ##
  expect.mod.size = 3,  # number of covariates included in BSTS model of counterfactual
  covariates.type = 'control'
)

## SIMULATION LIST HOLDER
simlist <- list()

## state space configuration used as label
key <- 'S4vignette'
## SImulations list (for comparisons, gridsearches; use list length==1 for single model run)
simlist[[ key ]] <- sim.config
## Simulation ID
sim.id <- round(10*as.numeric(Sys.time()))





###
## Function to simulate time series data or load saved simulation data
###
processSimData <- function(simlist, key, effect.type, 
                           dgp.prior.sd.weight, sim.id=NA)
{
  
      ##-------------------------------------------------------
    ### CREATING ILLUSTRATION SIMULATION IF NONE EXISTS
    data.filepath <- file.path(dir_proj, sprintf('__bsts_vignette_1_sim-priorSd%s_%s_df.csv',
                                                 dgp.prior.sd.weight, effect.type))
    if ( ! file.exists(data.filepath) ) {
      cat(sprintf('\nIllustration data file 1 not found in project dir:\n %s.\n Simulating new illustration data set.\n',dir_proj))
      ## RUN SIMULATION -  GENERATE TIME SERIES
      simlist <- runSimUpdateSimlist(simlist, effect.types = c(effect.type),
                                     sim.id = sim.id, plot.show = F, plot.save = F,     
                                     dgp.prior.sd.weight=dgp.prior.sd.weight)
      # ## Save simulation for reuse with multiple BSTS models
      # simcopy <- simlist[[key]]
      ## SAVE SIMULATED DATAFRAME TO FILE
      simdf <- simlist[[key]]$sim$df
      cols.to.front <- c('t','actor','y','x1','x2','x3','c1','c2','c3','b1','b2','b3','u','v','season.val')
      cols.to.back <- c('effect.type','t.post.intpd','group','group.color','match_id','match_pd')
      simdf <- simdf[, c(cols.to.front, cols.to.back)]
      write.csv(simdf, file=data.filepath, row.names=F, na='')
      cat(sprintf('Saved simulated data to file:\n %s',data.filepath))
    } else {
      cat(sprintf('Loading data file:\n %s',data.filepath))
      simdf <- read.csv(data.filepath, stringsAsFactors = F)
    }
    
    ##--------------------------- INITS ----------------------
    bsts.df <- NULL
    bsts.df1 <- NULL
    bsts.df2 <- NULL
    cov.df.wide1 <- NULL
    cov.df.wide2 <- NULL
    ##--------------------------------------------------------
    ### SUMMARIZE BSTS (single-observation) SERIES - WITH DIFFERENT COVARIATE PREDICTORS
    bsts.df1.filepath <- file.path(dir_proj,
                                   sprintf('__bsts_vignette_1_sim-priorSd%s_%s_agg_bsts_df1-NOctrl.csv',
                                   dgp.prior.sd.weight, effect.type))
    bsts.df2.filepath <- file.path(dir_proj,
                                   sprintf('__bsts_vignette_1_sim-priorSd%s_%s_agg_bsts_df2-ONEctrl.csv',
                                   dgp.prior.sd.weight, effect.type))
    # bsts.df3.filepath <- file.path(dir_proj, 'bsts_vignette_illustration_bsts-3-SYNTHctrl_df.csv')
    f1exists <- file.exists(bsts.df1.filepath) 
    f2exists <- file.exists(bsts.df2.filepath) 
    # f3exists <- file.exists(bsts.df3.filepath) 
    if ( file.exists(data.filepath) & any(!f1exists, !f2exists)) {  # !f3exists
      
      simdf <- read.csv(data.filepath, stringsAsFactors = F) ## don't auto convert chars to factor type
      simdf <- as_tibble(simdf)
      
      ## TREATMENT
      bsts.df <- simdf %>%
        dplyr::filter( 
          ! is.na(match_id), 
          group=='treatment'
        ) %>%
        group_by(t) %>%
        summarize(
          y_observed = mean(y, na.rm=T)
        ) 
      
      ## NO UNTREATED CONTROL GROUP - ONLY COVARIATES
      if (!f1exists) {
          cat(sprintf('\nIllustration data file 2 not found in project dir:\n %s.\n Aggregating new illustration data set.\n',dir_proj))
        cov.df.wide1 <- simdf %>%
          dplyr::filter( 
            ! is.na(match_id), 
            group=='control'
          ) %>%
          group_by(t) %>%
          dplyr::summarize(
            c1_mean = mean(c1, na.rm=T),
            c2_mean = mean(c2, na.rm=T),
            c3_mean = mean(c3, na.rm=T),
            c1_sd = sd(c1, na.rm=T),
            c2_sd = sd(c2, na.rm=T),
            c3_sd = sd(c3, na.rm=T),
            c1_skew = ifelse(length(c1)<=1, NA, skewness(c1, na.rm = T, type = 2)),
            c2_skew = ifelse(length(c2)<=1, NA, skewness(c2, na.rm = T, type = 2)),
            c3_skew = ifelse(length(c3)<=1, NA, skewness(c3, na.rm = T, type = 2))#,
          ) #%>% pivot_wider(names_from, values_from)
        bsts.df1 <- bsts.df %>% full_join(cov.df.wide1, by='t')
        bsts.df1$t <- NULL
        write.csv(bsts.df1, file=bsts.df1.filepath, row.names = F, na = '')
        cat(sprintf('Saved aggregated simulation data to file:\n %s',bsts.df1.filepath))
      } else {
          cat(sprintf('Loading data file:\n %s',bsts.df1.filepath))
          cov.df.wide1 <- read.csv(bsts.df1.filepath, stringsAsFactors = F)
      }
      
      ## 1 UNTREATED CONTROL GROUP  +  COVARIATES
      if (!f2exists) {
          cat(sprintf('\nIllustration data file 3 not found in project dir:\n %s.\n Aggregating new illustration data set.\n',dir_proj))
        cov.df.wide2 <- simdf %>%
          dplyr::filter( 
            ! is.na(match_id), 
            group=='control'
          ) %>%
          group_by(t) %>%
          dplyr::summarize(
            y_control = mean(y, na.rm=T),
            c1_mean = mean(c1, na.rm=T),
            c2_mean = mean(c2, na.rm=T),
            c3_mean = mean(c3, na.rm=T),
            c1_sd = sd(c1, na.rm=T),
            c2_sd = sd(c2, na.rm=T),
            c3_sd = sd(c3, na.rm=T),
            c1_skew = ifelse(length(c1)<=1, NA, skewness(c1, na.rm = T, type = 2)),
            c2_skew = ifelse(length(c2)<=1, NA, skewness(c2, na.rm = T, type = 2)),
            c3_skew = ifelse(length(c3)<=1, NA, skewness(c3, na.rm = T, type = 2))#,
          ) #%>% pivot_wider(names_from, values_from)
          bsts.df2 <- bsts.df %>% full_join(cov.df.wide2, by='t')
          bsts.df2$t <- NULL
          write.csv(bsts.df2, file=bsts.df2.filepath, row.names = F, na = '')
          cat(sprintf('Saved aggregated simulation data to file:\n %s\n',bsts.df2.filepath))
      } else {
          cat(sprintf('Loading data file:\n %s\n',bsts.df2.filepath))
          cov.df.wide2 <- read.csv(bsts.df2.filepath, stringsAsFactors = F)
      }
      
   
      
    }
    
    return(list(
      bsts.df1.filepath=bsts.df1.filepath,
      bsts.df2.filepath=bsts.df2.filepath,
      bsts.df1=bsts.df1,
      bsts.df2=bsts.df2
    ))
      
}

##=====================================================================
## ---------SCENARIOS---------------
## LOW DGP SD WEIGHT
dgp.prior.sd.weight.low <- .01
# ## HIGH DGP SD WEIGHT
# dgp.prior.sd.weight.high <- .1
##-----------------------------------
## First we simulate the data for the simulation scenario 1, in which 
## the prior SD is 0.01. 
##
## SIMULATE DATA AND RETURN DATA LIST OBJECT - LOW PRIOR SD
dat1 <- processSimData(simlist, key, effect.type, 
                       dgp.prior.sd.weight.low, 
                       sim.id)
# ## SIMULATE DATA AND RETURN DATA LIST OBJECT - HIGH PRIOR SD
# dat2 <- processSimData(simlist, key, effect.type, 
#                        dgp.prior.sd.weight.high, 
#                        sim.id)
```


\newpage

This vignette presents `R` code and a tutorial example of  Bayesian Counterfactual 
Analysis (BCA). This approach includes two main steps: (1) building a Bayesian 
structural time series (BSTS) model 
[Section 1](#Section1), and (2) using the BSTS model as a
counterfactual for causal inference [Section 2](#Section2).

* [**Section 1**](#Section1) includes complexity of the Bayesian approach. The basic structure of a BSTS model is local trend (state space) + seasonality (state space) + regression. Each component has several ways to define, and prior settings are slightly different. Thus, we aim to show step-by-step process of adding different components in [Section 1](#Section1) accompanied by checking resulting BSTS models, setting up Bayesian priors,and adding regression component (Spike and slab priors included). This part requires the `bsts` package in R: [https://cran.r-project.org/web/packages/bsts/bsts.pdf](https://cran.r-project.org/web/packages/bsts/bsts.pdf). 
* [**Section 2**](#Section2) shows how to assess causal effects using the BSTS model from [Section 1](#Section1) as a counterfactual, and is a straightforward process using the `CausalImpact` R package: [https://google.github.io/CausalImpact/CausalImpact.html](https://google.github.io/CausalImpact/CausalImpact.html)  


# 0. Simulated Data

First load the data simulated from a data generating process (DGP) with 

- a random walk with small step size in the trend (i.e., local level standard deviation [SD] = 0.01), 
- weekly seasonality with frequency of 1 per cycle (i.e., 52 weeks = 1 year), and 
- a positive linear trend over time.  

This data set includes the outcome series `y_observed`, and nine 
covariate series, `c1-c9`, from which the BSTS models that have regression
components will select their predictors. These covariates were created to have
some type of relevant structure (e.g., noisy linear trend or moderate correlation
with lagged mean of the outcome series) to add to the BSTS model via regression.

Note that the width limit prevents all columns from displaying, but the data 
`tibble` object summary displays the total number of rows and truncated
series with their corresponding data classes.
```{r, message=FALSE}
## load BSTS library
library(bsts)
library(CausalImpact)
library(tibble) ## load a data table class with convenience functions
## LOAD FROM FILE
df1 <- as_tibble(read.csv(dat1$bsts.df1.filepath)) ##convert table, print labels
print(df1)
```
We can plot this data to visualize the post-intervention change in the 
outcome series `y_observed`.
```{r outcome_plot, fig.dim = c(6,4), out.width="100%"}
npds <- nrow(df1)
intpd <- round(npds * 0.6)  # time period to split series (60% pre-, 40% post-)
## PLOT
plot(df1$y_observed, main='Simulated Outcome Time Series (Y)',ylab='Y',xlab='Time')
abline(v=intpd, lty=2)
legend('topleft',legend=c('observed','intervention'), pch=c(1,NA),lty=c(NA,2))
```
\newline
The question of interest for research and practice is whether there
is a significant effect caused by the intervention at time point
`t=312`. We will apply BSTS for counterfactual causal inference to 
answer this question in a manner robust to the shape of the onset and 
decay structure of the dynamic treatment effect in the post-intervention window. 

For this purpose, we first build a BSTS model based on observed data before the intervention, 
and the prediction of the BSTS model after the intervention will serve as a counterfactual to assess the causal effects of the intervention. 

Thus, we create the pre-intervention outcome series `y.pre.treat.NAs.post`
to pass into the `bsts()` function. 
Here we replace the post-intervention periods with `NA`'s that 
represent missing values within the `R` language. This is because the 
BSTS model is trained on the pre-intervention outcome data. 
We also define covariates as predictors to add a regression component
to the BSTS model ([Section 1.4](#Section1-4)). 
```{r}
## INDICES OF PRE-INTERVENTION and POST-INTERVENTION WINDOWS
pre.idx <- 1:(intpd-1)
post.idx <- intpd:npds
## Outcome (response) series
y <- df1$y_observed
## Train on y pre-treatment but NA's post-treatment
y.pre.treat.NAs.post <- c( y[pre.idx], rep(NA,length(post.idx)) )
## Then use the post-treatment response for causal impact estimation
post.period.response <- y[post.idx]
## Covariates (predictors) - data for the "formula = y ~ predictors" argument
predictors <- df1[ , ! names(df1) %in% 'y_observed']
```


# 1. Bayesian Structural Time Series (BSTS) Modeling {#Section1}

## 1.1. State Space Specification: Local Trend Only

The simplest BSTS model is with only the local trend in the state space. 
There are several state spaces in the `bsts` package for defining local trend including local level, 
local linear trend, student local linear trend, and generalized local linear trend.

In this section, we start with the simplest local trend, local level 
(see [Section 1.6](#Section1-6) for other types of local trend).

First, configure the model's state space by adding components to the 
state space list `st.sp`. Here `y.pre.treat.NAs.post` is passed into the state
space functions (after the state space list object `st.sp`)
as the outcome series being modeled. 
```{r}
## Initiate empty state space configuration list
st.sp <- list()
## Add local level to trend component of state space
st.sp <- AddLocalLevel(st.sp, y.pre.treat.NAs.post)
## Set BSTS MCMC iterations
bsts.niter <- 1e4 ## suggest on the order of 1k-10k at least
```
Then, fit the BSTS model by calling the `bsts()` function to run MCMC estimation 
for `bsts.niter` draws from the stationary distribution of the Markov chain, which  
(assuming convergence was reached) specifies the posterior predictive distribution.
This will be addressed below in [Section 1.6](#Section1-6)).
```{r}
## Fit BSTS model
bsts.fit <- bsts(y.pre.treat.NAs.post,
                 state.specification = st.sp,
                 niter = bsts.niter,
                 seed = rand.seed)
```
Visualizing the model's behavior can help build intuition about 
what the model is doing and, ideally, about how to improve its fit to the 
characteristics of the data set. To inspect the contributions of the model 
components, we write a function that will report the model's summary, 
plot the state space components, and if there is a regression in the model, 
it will plot the coefficients, predictors, and distribution of model sizes.
```{r, out.width="100%", fig.align="center", fig.dim=c(6, 4.2)}
## Define a function to summarize and visualize the BSTS model components 
getBstsSummaryPlots <- function(bsts.fit) {
  par(mfrow=c(1,1)) ## set plotting params to one image in plot window
  print(summary(bsts.fit))
  plot(bsts.fit, 'components')
  if (bsts.fit$has.regression) {
    plot(bsts.fit, 'coefficients', main='Coefficients')
    plot(bsts.fit, 'size', main='Model Size Distribution')
    plot(bsts.fit, 'predictors', main='Predictors')
  }
  plot(bsts.fit, 'state', 
       main='Observations on Fitted State Space with Forecast')
}
## Call our newly defined function
getBstsSummaryPlots(bsts.fit)
```
There appears to be a seasonal component to the time series, which is currently
being captured by the trend. However, this would be a poor model to use as a 
counterfactual because it does not capture how seasonality continues
after the training window. This is visible in the lack of seasonal pattern and
quickly widening forecast intervals in the plot of the trend component 
of the state space after the intervention period, t=312. 

Next, we plot the contributions to the model's state space against
the observed outcome (black dots in figure below) to help with visual 
understanding of this model's prediction, or fitted values (blue lines), 
and later for comparison with other models introduced below. This uses 
a custom function `plotBstsStateComps()` we created for this purpose, which
can be found in the `R/bsts_helper_functions.R` script in the
online repository. 
```{r, out.width="100%", fig.align="center", fig.dim=c(6, 4.2)}
check <- plotBstsStateComps(bsts.fit, intpd=intpd, return.val = T) 
```
This model appears to match the data with the trend only. 
However, this is merely accurate for short (e.g., one-step ahead) predictions 
within the training window. In terms of capturing the structure of the time 
series, this model is underspecified--while at the same time, 
it is essentially overfitted to the training data.  

Although the predicted values (blue lines) seem accurate as one-step ahead, 
in-sample predictions, the model would lose the seasonal information 
outside the training window (post intervention), leaving the counterfactual series
devoid of seasonality when used for causal inference computations
([Section 2](#Section2)).

Therefore, it is crucial to capture seasonality in the outcome time series 
and incorporate it into the BSTS model that will be used as the 
counterfactual for causal inference with the `CasualImpact()` function in
[Section 2](#Section2). 

## 1.2. State-Space Specification: Local Trend + Seasonality

To account for seasonality in the time series data generating process, 
we add a seasonal component to the state space defined by the number of seasons and the duration of each season. For instance, we use 52 periods with duration =1 to produce the state contribution of seasonal cycles (e.g., weekly periods each year). As a comparison, for daily data, 
it is recommended to use 7 for a 
day-of-week component with the duration of each season of 1.
```{r, out.width="100%", fig.align="center", fig.dim=c(6, 4.2)}
## Initiate empty state space configuration list
st.sp2 <- list()
## Add local level to trend component of state space
st.sp2 <- AddLocalLevel(st.sp2, y.pre.treat.NAs.post)
## Add seasonality to state space (52 weekly periods = 1 yearly cycle) 
st.sp2 <- AddSeasonal(st.sp2, y.pre.treat.NAs.post, 
                      nseasons = 52, season.duration = 1)
## Fit BSTS model and get summary plots
bsts.fit2 <- bsts(y.pre.treat.NAs.post ,
                 state.specification = st.sp2, 
                 niter = bsts.niter,
                 seed = rand.seed, ping=0)
getBstsSummaryPlots(bsts.fit2)
check2 <- plotBstsStateComps(bsts.fit2, intpd=intpd, return.val = T)
```
Following BSTS (and other forecasting) conventions, 
it is common to use a model performance metric, 
such as the one-step ahead prediction (forecast) error within sample
during the pre-intervention (or training) window. We might expect that the augmented
state space should improve the model performance (e.g., in terms of 
decreased MAE). However, the MAE of this model is now `r round(check2$mae, 3)`.

Here we have a seasonal component separate from the trend (which includes 
one the local level at this point). Now the state space of the fitted model 
exhibits the seasonal structure of the time series into the post-intervention 
forecast window. 

However, besides seasonality, the observed data (Y) also appears to have
a positive linear trend, which is not currently captured by the 
local level (default without slope or drift) of the state space trend. 
This is apparent in trend component plot where the upward linear 
trajectory before the intervention turns into a constant expectation after the 
intervention -- as a simple random walk where the expetation at `t` is 
the trend at `t-1` (also just the local level without slope or drift) 
plus Gaussian noise. Therefore, this seasonal model still does not capture the linear trend in the 
DGP and the fit could also be improved with more information about the outcome from 
covariate series with regression. But before moving on to addressing 
regression in BSTS models, we first detail the process of parameter tuning. 

A crucial step in any machine learning (ML) analysis is hyperparameter tuning,
which applies to our investigation of dynamic causal inference using a Bayesian
counterfactual approach drawing upon the ML tradition. Therefore,
adjusting the values of prior distributions in the Bayesian counterfactual
approach plays an important role in achieving adequate model fit for 
complex time series structures. The BSTS model should, of course, be able to 
mimic the observed outcome series pre-intervention and project that 
state space forward into the post-intervention window while also 
characterizing the uncertainty via credible intervals. 

Additionally, in terms of research design and process, 
prior parameter tuning represents an important step for researchers 
to incorporate information from theory and context into their empirical
analyses--coherently within a Bayesian framework. 

## 1.3. Bayesian Priors: Parameter Tuning

Setting up Bayesian priors is notorious for its complication. 
The conventional wisdom is to exploit information of the observed outcome. 
There are two main types of priors to set up for local level and seasonality,  priors for the variance of the state innovation errors and the initial value of the state at time 0, provided by Boom package.  
The former is defined by the option of `sigma.prior` created by `SdPrior` which describes the prior distribution for the standard deviation of the random walk increment (e.g., inverse Gamma priors). 
The latter one is `initial.state.prior` defined by `NormalPrior` to describe the prior distribution of the initial state vector (e.g., Gaussian distribution). If not defined, the default setting will be applied.
Examples include:
```
sigma.prior = SdPrior(sigma.guess= , 
                      sample.size = , 
                      initial.value = ,
                      fixed = , 
                      upper.limit = ),
                       
initial.state.prior = NormalPrior(mu= ,
                                  sigma= ,
                                  initial.value= ,
                                  fixed= ,
                                  upper.limit= )
```
Most of the particulars of prior elicitation we necessarily bound outside the 
scope of this tutorial vignette. Beginning at the assumption that the 
researcher has theoretical and/or contextual knowledge that can inform  
prior distribution attributes, we focus next on illustrating how to adjust 
the prior distribution settings for the `bsts()` function. 

In order to simplify the logic for specific values, we set parameter settings
for prior variances in terms of multiples of the empirical 
standard deviation of the observed outcome in the pre-intervention
window, `y[pre.idx]` (which is the same as `y.pre.treat.NAs.post` vector
within the `pre.idx` interval). 
```{r, out.width="100%", fig.align="center", fig.dim=c(6, 4.2)}
## Get outcome (Y) standard deviation to use for adjusting priors below
y.sd <- sd(y[pre.idx], na.rm = T)
## Initiate empty state space configuration list
st.sp3 <- list()
## Add local level to trend component of state space
st.sp3 <- AddLocalLevel(st.sp3, y.pre.treat.NAs.post, 
  initial.state.prior = NormalPrior(mu=1, sigma = 0.25 * y.sd, fixed = FALSE),
  initial.y = y.pre.treat.NAs.post[1]
)
## Add seasonality to state space (52 weekly periods = 1 yearly cycle) 
st.sp3 <- AddSeasonal(st.sp3, y.pre.treat.NAs.post, 
  nseasons = 52, 
  season.duration = 1, 
  sigma.prior = SdPrior(
    sigma.guess = 0.01 * y.sd,      ##try a low weight of observed Y SD
    sample.size = round(0.1 * (intpd-1)), ## portion of sample size (pre-int.)
    upper.limit= 1.5 * y.sd ## use SD of observed Y to set upper limit
  ),
  initial.state.prior = NormalPrior(
    mu = 0,   
    sigma = 1.0 * y.sd  ## increase initial state prior sigma
  )
)
## Fit BSTS model:
bsts.fit3 <- bsts(y.pre.treat.NAs.post,
                 state.specification = st.sp3,
                 niter = bsts.niter,
                 seed = rand.seed, ping=0)
getBstsSummaryPlots(bsts.fit3)
check3 <- plotBstsStateComps(bsts.fit3, intpd=intpd, return.val = T) 
```
The MAE of this model is now `r round(check3$mae, 3)`.

This model does not appear to improve (in terms of MAE),
but the model now has seasonal structure, in addition to the local level
captured in the trend component, which collectively would inform a better
counterfactual post-intervention. So, essentially, the addition of seasonal
structure reduces a portion of the overfitting against current data
in order to incorporate a temporal structure (seasonality) 
that can continue into the post-intervention forecast.
This, in turn, will be used as the counterfactual for causal inference. 

Beyond seasonality, another way to incorporate structure from 
the training window into the post-intervention window
is including a regression component in BSTS model. Assuming the 
covariates included in the regression carry at least some information
about the outcome series pre-intervention (and that relationship
does not change for the covaritate post-intervention), then including 
regression in the BSTS model should generally improve the model's performance 
as a counterfactual (i.e., as a representation of the pre-intervention trend 
of the outcome series projected forward into the post-intervention window).
In using BSTS for causal inference, the researcher can include 
covariates with information about (i.e., correlation with) the outcome 
of interest and therefore improve the representativeness of the 
counterfactual series.

## 1.4. Covariate Information: Local Trend + Seasonality + Regression {#Section1-4}

### 1.4.1. Regression `formula` in BSTS function

This adds a static regression component (i.e., time-invariant betas) with
covariate series in the `predictors` dataframe, which is used as
the `data` input for the `bsts()` function. When we do not specify this, 
the default setting is 1, which entails the model choosing the one
covariate that best explains the outcome, Y.  

In this model we set `expected.model.size=3` to allow the model to 
incorporate information from, on average, three covariate series in the
regression component. The default setting for this parameter is 
`expected.model.size=1`.

```{r, out.width="100%", fig.align="center", fig.dim=c(6, 4.2)}
## Initiate empty state space configuration list
st.sp4 <- list()
## Add local level to trend component of state space
st.sp4 <- AddLocalLevel(st.sp4, y.pre.treat.NAs.post,
  initial.state.prior = NormalPrior(mu=1, sigma = .25 * y.sd, fixed = FALSE),
  initial.y = y.pre.treat.NAs.post[1]
)
## Add seasonality to state space (52 weekly periods = 1 yearly cycle) 
st.sp4 <- AddSeasonal(st.sp4, y.pre.treat.NAs.post, 
  nseasons = 52, 
  season.duration = 1, 
  sigma.prior = SdPrior(
    sigma.guess = 0.01 * y.sd,      ## use SD of observed y
    sample.size = round(0.1 * (intpd-1)),  ## use portion of pre-int window
    upper.limit= 1.5 * y.sd ## use SD of observed y to set upper limit
  ),
  initial.state.prior = NormalPrior(
    mu= 0,  
    sigma= 1.0 * y.sd  
  )
)
## Fit BSTS model
bsts.fit4 <- bsts(y.pre.treat.NAs.post ~ . ,
                 state.specification = st.sp4,
                 data = predictors,  ## covariates
                 niter = bsts.niter, 
                 expected.model.size=3, ##expected number of covariates in model
                 seed = rand.seed, ping=0)
getBstsSummaryPlots(bsts.fit4)
check4 <- plotBstsStateComps(bsts.fit4, intpd=intpd, return.val = T)
```
The MAE of this model is now `r round(check4$mae, 3)`.

### 1.4.2.  Variable Selection: Spike-and-Slab Priors

Having proper variables in regression is a crucial step in building a counterfactual time series
that sufficiently approximates (i.e., correlates to a sufficient degree with) 
the outcomes series in the pre-intervention window. 

One of the advantages of BSTS models is that variable selection among covariates 
is incorporated into the model within a Bayesian framework via 
spike-and-slab priors. 

There are two main ways to modify the the number of covariate series included
in the BSTS model, which is also referred to as the "model size," or 
size of the regression component of the model:

1. Pass `expected.model.size` argument into `bsts()` directly
2. Create a `SpikeSlabPrior` object to pass into `bsts()` by:
    1. Using `expected.model.size` argument of `SpikeSlabPrior()`
    2. Specifying inclusion probability for each covariate in `SpikeSlabPrior()`

First, the simplest method is to set the `expected.model.size` attribute 
(of the `SpikeSlabPrior`) by passing the `expected.model.size` argument 
into the `bsts()` function directly.
```{r, out.width="100%", fig.align="center", fig.dim=c(6, 11)}
st.sp5 <- st.sp4  ## copy previous state space config to new model
#=================
# Option 1. Specify expected model size (internally creates SpikeSlabPrior)
#----------------
#   This uniformly sets prior (spike) probabilities = (1 / expected.model.size)
bsts.fit5 <- bsts(y.pre.treat.NAs.post ~ .,
                 state.specification = st.sp5,
                 data = predictors,
                 expected.model.size = 5,  ## argument passed to SpikeSlabPrior
                 niter = bsts.niter,
                 seed = rand.seed, ping=0)
summary(bsts.fit5)
par(mfrow=c(2,1))
plot(bsts.fit5, 'coefficients', main='Expected Size = 5')
plot(bsts.fit4, 'coefficients', main='Expected Size = 3')
```
Second, the user can create a `SpikeSlabPrior` object to pass into the `bsts()`
function. One way to do this is by using the `expected.model.size` argument 
of `SpikeSlabPrior()`. This allows you to set the expected model size in a 
simple manner when all covariates are assumed to have equal, naive inclusion
probabilities. This is just like the first method above but the intermediate
step of creating a `SpikeSlabPrior` object enables the researcher to adjust 
the expected model size and all other regression prior parameter settings 
in the same step. 
```{r, out.width="100%", fig.align="center", fig.dim=c(6, 4.2)}
st.sp6 <- st.sp5  ## copy previous state space config to new model
#=================
# Option 2. Create SpikeSlabPrior object and pass it into BSTS function
#-----------------
###---------------
#  2A. Set expected.model.size in SpikeSlabPrior (with other options)
priorObjA <- SpikeSlabPrior(
  x = model.matrix(y.pre.treat.NAs.post ~ ., data=predictors),
  y = y.pre.treat.NAs.post,
  expected.model.size = 3, ## size in SpikeSlabPrior
  expected.r2 = .9,
  prior.df = .1,## weight in terms of observation count
  prior.information.weight = .1
) 

# Run the bsts model with the SpikeSlabPrior object ‘priorObjA’
bsts.fit6 <- bsts(y.pre.treat.NAs.post ~ ., 
                  state.specification = st.sp6,
                  data = predictors,
                  niter = bsts.niter,
                  prior= priorObjA, ## spike-and-slab priors defined above
                  seed = rand.seed, ping = 0)
getBstsSummaryPlots(bsts.fit6)
check6 <- plotBstsStateComps(bsts.fit6, intpd = intpd, return.val = T)
```
The MAE of this model is now `r round(check6$mae, 3)`.

Finally, the other way to create a `SpikeSlabPrior` object to pass
into the `bsts()`function is by specifying prior inclusion probabilities
(and estimates) for each covariates series in `predictors`. This is useful
when the researcher has prior knowledge that certain covariates are 
more likely to be important contributors to the counterfactual series
and should therefore be included in the model in more iterations 
(i.e., more MCMC draws from the posterior predictive distribution). 
```{r, out.width="100%", fig.align="center", fig.dim=c(6, 4.2)}
st.sp7 <- st.sp6  ## copy previous state space config to new model
###---------------
# 2B. Specify prior.inclusion.probabilities for each covariate
#   where length of prior spikes and means vectors should equal the number of
#    covariates
#   (i.e., this example with vector lengths = 11 implies
#      ‘data’ has 11 columns) <-- this includes intercept in example below
prior.spikes <- c(.7,.8,.9,.1,.1,.1,.1,.1,.1,.1) ## +1 column for intercept (?)
prior.means <- c(.2,.2,.3,0,0,0,0,0,0,0) ## +1 column for intercept (?)
# Directly set prior spike probabilities for each covariate in the prior object
priorObjB <- SpikeSlabPrior(x = model.matrix(y.pre.treat.NAs.post ~ ., 
                                             data=predictors),
                            y = y.pre.treat.NAs.post,
                            expected.r2 = .9,
                            prior.df = .1,
                            prior.information.weight = .1, ##  ~ obs. count
                            prior.inclusion.probabilities = prior.spikes,
                            optional.coefficient.estimate = prior.means)
# Run the bsts model with the SpikeSlabPrior object ‘priorObjB’
bsts.fit7 <- bsts(y.pre.treat.NAs.post ~ ., 
                  state.specification = st.sp7,
                  data = predictors,
                  niter = bsts.niter,
                  prior= priorObjB, ## spike-and-slab prior defined above
                  seed = rand.seed, ping = 0)
getBstsSummaryPlots(bsts.fit7)
check7 <- plotBstsStateComps(bsts.fit7, intpd = intpd, return.val = T)
```
The MAE of this model is now `r round(check7$mae, 3)`.

## 1.5. Local Trends Comparison: Level vs. Linear Short-Term and Long(er)-Term

Besides the default state space containing only a local level component, 
we can evaluate different state space configurations, such as those
including a local linear trend and semi-local linear trend.

### 1.5.0. Local Level (Trend without Slope)

This was the simple model introduced above. As a state space without
a linear trend, this model will serve as a baseline for comparison 
with other state space configurations that contain a type of linear trend. 
Given that we know our simulation DGP includes a small positive linear trend,
this should accentuate performance differences between different types of
local trends (specifically, those with vs. without a slope) to make evident the 
differences between the types of linear trend components that can be 
added to the BSTS model's state space. 

### 1.5.1. Local Linear Trend (Trend with Level and Slope)

The local linear trend is useful for short term predictions of relatively 
well-behaved time series. 
```{r, out.width="100%", fig.align="center", fig.dim=c(6, 4.2)}
## Initiate empty state space configuration list
st.sp8 <- list()
## Add local linear trend component of state space
st.sp8 <- AddLocalLinearTrend(st.sp8, y.pre.treat.NAs.post, 
  level.sigma.prior=SdPrior(sigma.guess=.01 * y.sd, 
                            sample.size=round( 0.1 * (intpd-1)), 
                            upper.limit = 1.5 * y.sd,
                            fixed = F), 
  slope.sigma.prior=SdPrior(sigma.guess=.0001 * y.sd, 
                            sample.size=round( 0.1 * (intpd-1)), 
                            upper.limit = 1.5 * y.sd,
                            fixed = F), 
  initial.level.prior=NormalPrior(mu=1, sigma=.001 * y.sd, fixed = F), 
  initial.slope.prior=NormalPrior(mu=0, sigma=.001 * y.sd, fixed = F)
)
## Add seasonality to state space
st.sp8 <- AddSeasonal(st.sp8, y.pre.treat.NAs.post, 
  nseasons = 52, 
  season.duration = 1, 
  sigma.prior = SdPrior(
    sigma.guess = 0.01 * y.sd,  
    sample.size = round( 0.1 * (intpd-1)),    
    upper.limit = 1.5 * y.sd
  ), 
  initial.state.prior = NormalPrior(
    mu = 0,   
    sigma = 1 * y.sd  
  )
)
## Fit BSTS model
bsts.fit8 <- bsts(y.pre.treat.NAs.post ~ . ,
                 state.specification = st.sp8,
                 data = predictors, 
                 niter = bsts.niter, 
                 expected.model.size=3, ## instead of:  prior = priorObjB
                 seed=rand.seed, ping = 0)

## CALL OUR CUSTOM BSTS SUMMARY
getBstsSummaryPlots(bsts.fit8)
check8 <- plotBstsStateComps(bsts.fit8, intpd = intpd, return.val = T)
```
The MAE of this model is now `r round(check8$mae, 3)`.

### 1.5.2. Semilocal Linear Trend (Trend with Level and Slope with AR(1) Drift)

The semilocal linear trend component in the BSTS model state space is 
useful for longer-term forecasts wherein the linear trend persists longer, 
so tighter prediction bounds are reasonable over longer post-intervention 
window. 
```{r, out.width="100%", fig.align="center", fig.dim=c(6, 4.2)}
## Initiate empty state space configuration list
st.sp9 <- list()
## Add semilocal linear trend component of state space
st.sp9 <- AddSemilocalLinearTrend(st.sp9, y.pre.treat.NAs.post, 
  level.sigma.prior=SdPrior(
    sigma.guess=.001 * y.sd, 
    sample.size=round( 0.1 * (intpd-1)), 
    upper.limit = 1.5 * y.sd, 
    fixed = F),
  slope.mean.prior=NormalPrior(
    mu = 0, 
    sigma = .001 * y.sd), 
  slope.ar1.prior=Ar1CoefficientPrior(
    mu = 0, 
    sigma = .001 * y.sd, 
    force.stationary = FALSE, 
    force.positive = FALSE),
  slope.sigma.prior=SdPrior(
    sigma.guess=.0001 * y.sd, 
    sample.size=round( 0.1 * (intpd-1))),
  initial.level.prior=NormalPrior(
    mu = 0,
    sigma = .001 * y.sd, 
    fixed = F),
  initial.slope.prior=NormalPrior(
    mu = 0, 
    sigma = .001 * y.sd, 
    fixed = F)
)
## Add seasonality to state space
st.sp9 <- AddSeasonal(st.sp9, y.pre.treat.NAs.post, 
  nseasons = 52, 
  season.duration = 1, 
  sigma.prior = SdPrior(
    sigma.guess = .01 * y.sd,   
    sample.size = round( 0.1 * (intpd-1)),    
    upper.limit= 1.5 * y.sd
  ), 
  initial.state.prior = NormalPrior(
    mu= 0,   
    sigma = 1 * y.sd,  
  )
)
## Fit BSTS model
bsts.fit9 <- bsts(y.pre.treat.NAs.post ~ . ,
                 state.specification = st.sp9,
                 data = predictors,  
                 niter = bsts.niter, 
                 expected.model.size=3,
                 seed=rand.seed, ping=0)
getBstsSummaryPlots(bsts.fit9)
check9 <- plotBstsStateComps(bsts.fit9, intpd = intpd, return.val = T)
```
The MAE of this model is now `r round(check9$mae, 3)`.

Zooming into the first 100 periods shows how the BSTS model learns the structure
of the time series through the first couple of cycles that train the 
the seasonality and regression structures into the fitted model (via
recursive least squares in the Kalman filter). 

```{r, out.width="100%", fig.align="center", fig.dim=c(9, 4.2)}
par(mfrow=c(1,2), mar=c(4,4,.5,1))
plotBstsStateComps(bsts.fit9, intpd=intpd, pd.ids=1:104, title.show=F)##2 cycles
plotBstsStateComps(bsts.fit9, intpd=intpd, pd.ids=1:520, title.show=F)##10 cycles
```

## 1.6. MCMC Diagnostics: Checking Convergence and Fit {#Section1-6}

To check the convergence of the model estimation procedure and inspect 
the model's state space component contributions, we wrap a custom 
function created for this analysis, `bstsPostPredChecks()`, 
inside a formatting function, `getBstsDiagnosticPlots()`. Calling this on
several candidate BSTS models `bsts.fit`, `bsts.fit2`,
`bsts.fit8`, `bsts.fit9`, allows for comparison. 

Draws from the posterior distribution of the Markov chain(s)--once
converged at the stationary distribution--are used to estimate the 
model prediction at each time period though 
Markov chain Monte Carlo (MCMC) estimation. However, when the Markov chains
have not yet converged (usually due to insufficient MCMC burn-in period
or sampled iterations), then the iterations cannot be treated as draws from
the stationary distribution to sample the posterior predictive distribution. 
Thus, the estimates may be unstable and/or biased, so users must assess 
convergence of the MCMC chains. 

```
TODO: There are several ways to check the convergence of MCMC including the trace plots, Heidelberger-Welch tests, and Geweke diagnostic tests. We may evalue autocorrelation using ACF/PACF autocorrelation plots and Durbin-Watson tests. Precision was estimated from mean absolute 1-step prediction errors and range. 
```

Similarly, there is need to assess how the fitted model fits the observed data, 
in terms of how well new samples simulated from the fitted model create 
simulated distribution(s) that resemble the observed value(s). For this purpose, 
we examine MCMC convergence trace figures and plot model fit 
checks for the posterior predictive distribution of the outcome
(Y, top row panels) and the standardized residuals (bottom row panels). 
```{r, out.width="100%", fig.align="center", fig.dim=c(12, 8)}  
###
## Define a funciton to call all of our plotting, 
##    diagnostics and converngence checks functions
###
getBstsDiagnosticPlots <- function(bsts.fit, return.val=F) {
  par(mfrow=c(1,1))
  checks <- bstsPostPredChecks(bsts.fit, save.plot = F, return.val = T)
  cat('MCMC Convergence Diagnostics:\n')
  cat(checks$summary)
  if(return.val)
    return(checks)
}
```
In the first column, the trace of the Markov chain (mean of draws per period) 
is shown for the posterior predictive distribution of the outcome (Y). 
For model fit, the observed and predicted values of Y are compared (top-center), 
where tighter alignment indicates better fit. 

Additionally, using the maximum value of Y as an auxiliary statistic, 
the Bayesian p-val presents the proportion 
of maximum Y values (from MCMC) that are larger than the observed largest 
value of Y. Smaller values of Bayesian p-val indicate worse fit, which offers a 
similar interpretation to the frequentist null hypothesis statistical test 
(NHST) under a null assumption of a well fitting model. 
Values of Bayesian p-val >= alpha (conventionally 0.05) would therefore not reject the 
null of good fit, whereas Bayesian p-val < alpha indicates problem(s) of fit to 
be addressed (e.g., by increasing MCMC iterations, or respecifying the state space).

```
##TODO: ADD explantion about THE MCMC CONVERGENCE CHECKS: Geweke, H&W 
stationarity CMV and halfwidth-mean ratio check
```
\newpage
```{r, out.width="100%", fig.align="center", fig.dim=c(12, 8)}
## Baseline (Trend = local level)
getBstsDiagnosticPlots(bsts.fit)
```
\newpage
```{r, out.width="100%", fig.align="center", fig.dim=c(12, 8)}
## Seasonality Baseline
getBstsDiagnosticPlots(bsts.fit2)
```
\newpage
```{r, out.width="100%", fig.align="center", fig.dim=c(12, 8)}
## Regression, Seasonality, Trend = Local linear
getBstsDiagnosticPlots(bsts.fit8)
```
\newpage
```{r, out.width="100%", fig.align="center", fig.dim=c(12, 8)}
## Regression, Seasonality, Trend = Semilocal linear
getBstsDiagnosticPlots(bsts.fit9)
```


Note how each transition between diagnostic panels contrasted here
(from `bsts.fit` to `bsts.fit2`, from `bsts.fit2` to `bsts.fit8`, 
and `bsts.fit8` to `bsts.fit9` ) exhibits 
incremental improvement in the following visually discernible ways that also 
relate to quantifiable fit improvement (i.e., decreased MAE)

1. Adding seasonality in `bsts.fit2` begins to address the baseline model's
overly narrow prediction distribution 
2. Changing trend to local linear trend, and including regression, in `bsts.fit8` scales the predicted SD to the observed SD; however, the predictions are shifted (overestimated) and the standardized one-step
ahead prediction errors now exhibit non-normality and worsened autocorrelation. 
3. Changing trend to semilocal linear trend (and still including regression) in 
`bsts.fit9` simultaneously (a) fixes the bias in the predicted distribution
(realigned with observed distribution) and fixes the (b) non-normality
and (c) autocorrelation problems in the standardized one-step ahead prediction 
(i.e., forecast) error. 

With all convergence checks passed, and model diagnostics that can be 
quantitatively and qualitatively characterized as well fitting, 
we now have a BSTS model ready to serve as the counterfactual
for dynamic causal inference.


# 2. Dynamic Causal Inference: BSTS as Counterfactual {#Section2}

The preferred fitted bsts model `bsts.fit9` (i.e., the model with the least 
pre-intervention, one-step-ahead cumulative absolute prediction error) 
can now be passed into the `CausalImpact()`function. 
This will use `bsts.fit9`, which was fitted on the pre-intervention 
data, in order to forecast (i.e., predict outside of the pre-intervention
sample time window) the counterfactual series (i.e., the hypothetical 
outcome series if there had been no exposure to treatment).  The pointwise 
causal impact of the intervention is then computed as the 
difference between the predicted (counterfactual untreated outcome) and 
observed (actual treated outcome). The cumulative impact estimate is the 
cumulative sum of the pointwise impact estimates. 

Here we compare the causal inference results for two different 
counterfactuals (i.e., two different BSTS models) that differ in terms of 
their trend component: 

* `bsts.fit8` has a local linear trend (suited for shorter forecasts)
* `bsts.fit9` has a semilocal linear trend (suited for longer forecasts)

Below we echo the summary of causal inference results for comparing these
candidate models.
```{r}
## Causal impact estimation: fitted BSTS model forecasts the counterfactual
impact8 <- CausalImpact(bsts.model = bsts.fit8,
                        post.period.response = post.period.response,
                        alpha=0.05, model.args=list(niter = bsts.niter))
impact9 <- CausalImpact(bsts.model = bsts.fit9,
                        post.period.response = post.period.response,
                        alpha=0.05, model.args=list(niter = bsts.niter))
summary(impact8)
summary(impact9)
```
The `CausalImpact` package includes a convenience function to print a 
helpful (i.e., plain English) explanation of these Bayesian counterfactual 
analysis results from the BSTS model.
```{r}
summary(impact9, 'report')
```

In paragraph formatting, this report would look as follows:

> `r sprintf('%s', gsub('\n','<br /><br />  ',impact9$report))`

Then plotting the causal impact figures (original, pointwise, cumulative) is
useful for visually assessing the onset and decay structure of the 
dynamic treatment effect. In simulation scenario, the DGP has an inverse 
U-shape trajectory post intervention. Therefore the onset and
decay structure of the dynamic causal effect creates an s-shaped cumulative 
effect curve, which becomes cumulatively significant early and remains so 
through the post-intervention window. 

The 95% Bayesian credible intervals of the first model's 
(trend = local linear) posterior predictive distribution widen more quickly 
over time and display substantially more uncertainty in
the post-intervention window than the intervals of second model
(trend = semilocal linear). 
```{r, out.width="100%", fig.align="center", fig.dim=c(5.5, 8)}
plot(impact8); plot(impact9)
```
Finally, we can print the results table of pointwise estimates of the ATT, along 
with 95% Bayesian credible intervals from the posterior predictive distribution.
In this example, we take the `$series` attribute of the `impact9` object
and add columns for the event time and significance codes ('*') where
the pointwise interval does not contain zero. 

Due to the time series length, we truncate the output within the interval from 
1 period before the intervention to 20 periods after the intervention. 
```{r}
## Show Pointwise ATT Estimates from BSTS CausalImpact
restbl <- as_tibble(impact9$series)
restbl$event.time <- (1:npds) - intpd
restbl$`(sig.)` <- apply(restbl[,c('point.effect.lower','point.effect.upper')],
                       1, function(x){ ifelse(prod(x)>0,'*',"") })
rescols <- c('event.time','point.effect','(sig.)',
             'point.effect.lower', 'point.effect.upper')
restbl <- restbl[,rescols]
knitr::kable(restbl[(intpd-1):(intpd+26), ], n = 28, digits = 4, 
             caption = 'Pointwise ATT Estimates of BCA')
```

The same process can then be followed to return the cumulative effect estimates 
for each post-intervention period along with their credible intervals. 
```{r}
## Show Cumulative ATT Estimates from BSTS CausalImpact
cumutbl <- as_tibble(impact9$series)
cumutbl$event.time <- (1:npds) - intpd
cumutbl$`(sig.)` <- apply(cumutbl[,c('cum.effect.lower','cum.effect.upper')],
                       1, function(x){ ifelse(prod(x)>0,'*','') })
cumucols <- c('event.time','cum.effect','(sig.)',
             'cum.effect.lower', 'cum.effect.upper')
cumutbl <- cumutbl[,cumucols]
knitr::kable(cumutbl[(intpd-1):(intpd+26), ], n = 28, digits = 4,
             caption = 'Cumulative ATT Estimates of BCA')
```
This concludes the vignette illustrating how to use BSTS as the predictive model
in a Bayesian counterfactual approach to dynamic causal inference. 

Please note that references not yet included will be added to a future version of 
this document. 