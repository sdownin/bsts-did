---
title: "Bayesian Structural Time Series (BSTS) Illustration & Tutorial"
output: pdf_document
---

This is a tutorial and illustration for running Bayesian structural time series 
(BSTS) models, including configuring the state space and checking model diagnostics. 
```{r initExclude, setup, message=FALSE, include=FALSE}
rm(list=ls())
library(plyr)
library(dplyr)
library(tidyr)
library(tibble)
library(CausalImpact)
library(bsts)
library(did)
library(ggpubr)
library(cowplot)
library(coda)
library(Boom)
library(BoomSpikeSlab)
library(e1071)
library(forecast)  ## # library(sarima); library(qualV)
## reproducibility
rand.seed <- 9598677

set.seed(rand.seed)  

## Directories
dir_proj <- 'C:\\Users\\sdr8y\\OneDrive - University of Missouri\\Research\\BSTS'
dir_ext <- 'D:\\BSTS_external'
dir_plot <- file.path(dir_proj, 'plots')
dir_r <- file.path(dir_proj,'R')
##  file prefix for saving images, writing outputs, etc.
prefix <- 'bsts-illus_vignette_'

## Load simulation functions - Actor index vectorized simulation
source(file.path(dir_r,'single_intervention_sim_vec.R')) 
## Setting up and adding state space components to state.space list
source(file.path(dir_r,'bsts_helper_functions.R')) 
## BSTS vs. DiD comparison and sensitivity analysis
source(file.path(dir_r,'bsts_did_comparison_functions.R')) 

## Knitr root dir - PDF rendering of notebook
knitr::opts_knit$set(root.dir = dir_proj)

## MAIN SIM SETTINGS
n <- 100  ## number of actors (i.e., number of time series)
npds <- 520
intpd <- round( npds * .6 )
effect.type <- c('constant') ##  c('constant','geometric','quadratic') ## c('quadratic')  
bsts.niters <- list(sm.start = 50, sm.max = 100, lg.start = 500, lg.max = 1000)  ## lg=10k for full run
bsts.ctrl.cats <- NA

##
sim.config <- list(
  ##--------Simulation settings--------------
  n = n,    ## Number of firms
  npds = npds,  ## Number of periods
  intpd = intpd, ## #intervention period = (5/6)'ths of the total periods 
  noise.level = 1.0, ## stdev of simulated noise terms
  prior.sd.scenario = 'sd.low', ## BSTS Prior SD scenario (high vs. low uncertainty in priors
  treat.rule = 'random', 
  treat.prob =  0.5,  ## ifelse(treat.rule=='random', 0.5, 1), 
  treat.threshold = 1, ## ifelse(treat.rule=='random', 1, 0.5),
  seasonality = TRUE,
  dgp.nseasons= 52,  ## ifelse(seasonality, dgp.nseasons, NA), 
  dgp.freq=  1, ##ifelse(seasonality, dgp.freq, NA),
  rand.seed = rand.seed,
  ## Dynamic treatment effect  (quadratic polynomial)
  w0 = 1.0,  ## constant
  w1 = 0.03, ## linear
  w2 = -0.00333 /sqrt(npds), ## quadratic
  w2.shift = -round( sqrt(npds)*.7 ), ## quadratic shift rightward (make all of U-shape after intervention)
  ##
  expect.mod.size = 3,  # number of covariates included in BSTS model of counterfactual
  covariates.type = 'control'
)

## SIMULATION LIST HOLDER
simlist <- list()

## state space configuration used as label
key <- 'base'
## SImulations list (for comparisons, gridsearches; use list length==1 for single model run)
simlist[[ key ]] <- sim.config
## Simulation ID
sim.id <- round(10*as.numeric(Sys.time()))





###
## Function to simulate time series data or load saved simulation data
###
processSimData <- function(simlist, key, effect.type, 
                           dgp.prior.sd.weight, sim.id=NA)
{
  
      ##-------------------------------------------------------
    ### CREATING ILLUSTRATION SIMULATION IF NONE EXISTS
    data.filepath <- file.path(dir_proj, sprintf('__bsts_vignette_1_sim-priorSd%s_%s_df.csv',
                                                 dgp.prior.sd.weight, effect.type))
    if ( ! file.exists(data.filepath) ) {
      cat(sprintf('\nIllustration data file 1 not found in project dir:\n %s.\n Simulating new illustration data set.\n',dir_proj))
      ## RUN SIMULATION -  GENERATE TIME SERIES
      simlist <- runSimUpdateSimlist(simlist, effect.types = effect.type,
                                     sim.id = sim.id, plot.show = F, plot.save = F,     
                                     dgp.prior.sd.weight=dgp.prior.sd.weight)
      # ## Save simulation for reuse with multiple BSTS models
      # simcopy <- simlist[[key]]
      ## SAVE SIMULATED DATAFRAME TO FILE
      simdf <- simlist[[key]]$sim$df
      cols.to.front <- c('t','actor','y','x1','x2','x3','c1','c2','c3','b1','b2','b3','u','v','season.val')
      cols.to.back <- c('effect.type','t.post.intpd','group','group.color','match_id','match_pd')
      simdf <- simdf[, c(cols.to.front, cols.to.back)]
      write.csv(simdf, file=data.filepath, row.names=F, na='')
      cat(sprintf('Saved simulated data to file:\n %s',data.filepath))
    } else {
      cat(sprintf('Loading data file:\n %s',data.filepath))
      simdf <- read.csv(data.filepath, stringsAsFactors = F)
    }
    
    ##--------------------------- INITS ----------------------
    bsts.df <- NULL
    bsts.df1 <- NULL
    bsts.df2 <- NULL
    cov.df.wide1 <- NULL
    cov.df.wide2 <- NULL
    ##--------------------------------------------------------
    ### SUMMARIZE BSTS (single-observation) SERIES - WITH DIFFERENT COVARIATE PREDICTORS
    bsts.df1.filepath <- file.path(dir_proj,
                                   sprintf('__bsts_vignette_1_sim-priorSd%s_%s_agg_bsts_df1-NOctrl.csv',
                                   dgp.prior.sd.weight, effect.type))
    bsts.df2.filepath <- file.path(dir_proj,
                                   sprintf('__bsts_vignette_1_sim-priorSd%s_%s_agg_bsts_df2-ONEctrl.csv',
                                   dgp.prior.sd.weight, effect.type))
    # bsts.df3.filepath <- file.path(dir_proj, 'bsts_vignette_illustration_bsts-3-SYNTHctrl_df.csv')
    f1exists <- file.exists(bsts.df1.filepath) 
    f2exists <- file.exists(bsts.df2.filepath) 
    # f3exists <- file.exists(bsts.df3.filepath) 
    if ( file.exists(data.filepath) & any(!f1exists, !f2exists)) {  # !f3exists
      
      simdf <- read.csv(data.filepath, stringsAsFactors = F) ## don't auto convert chars to factor type
      simdf <- as_tibble(simdf)
      
      ## TREATMENT
      bsts.df <- simdf %>%
        dplyr::filter( 
          ! is.na(match_id), 
          group=='treatment'
        ) %>%
        group_by(t) %>%
        summarize(
          y_treatment = mean(y, na.rm=T)
        ) 
      
      ## NO UNTREATED CONTROL GROUP - ONLY COVARIATES
      if (!f1exists) {
          cat(sprintf('\nIllustration data file 2 not found in project dir:\n %s.\n Aggregating new illustration data set.\n',dir_proj))
        cov.df.wide1 <- simdf %>%
          dplyr::filter( 
            ! is.na(match_id), 
            group=='control'
          ) %>%
          group_by(t) %>%
          dplyr::summarize(
            c1_mean = mean(c1, na.rm=T),
            c2_mean = mean(c2, na.rm=T),
            c3_mean = mean(c3, na.rm=T),
            c1_sd = sd(c1, na.rm=T),
            c2_sd = sd(c2, na.rm=T),
            c3_sd = sd(c3, na.rm=T),
            c1_skew = ifelse(length(c1)<=1, NA, skewness(c1, na.rm = T, type = 2)),
            c2_skew = ifelse(length(c2)<=1, NA, skewness(c2, na.rm = T, type = 2)),
            c3_skew = ifelse(length(c3)<=1, NA, skewness(c3, na.rm = T, type = 2))#,
          ) #%>% pivot_wider(names_from, values_from)
        bsts.df1 <- bsts.df %>% full_join(cov.df.wide1, by='t')
        bsts.df1$t <- NULL
        write.csv(bsts.df1, file=bsts.df1.filepath, row.names = F, na = '')
        cat(sprintf('Saved aggregated simulation data to file:\n %s',bsts.df1.filepath))
      } else {
          cat(sprintf('Loading data file:\n %s',bsts.df1.filepath))
          cov.df.wide1 <- read.csv(bsts.df1.filepath, stringsAsFactors = F)
      }
      
      ## 1 UNTREATED CONTROL GROUP  +  COVARIATES
      if (!f2exists) {
          cat(sprintf('\nIllustration data file 3 not found in project dir:\n %s.\n Aggregating new illustration data set.\n',dir_proj))
        cov.df.wide2 <- simdf %>%
          dplyr::filter( 
            ! is.na(match_id), 
            group=='control'
          ) %>%
          group_by(t) %>%
          dplyr::summarize(
            y_control = mean(y, na.rm=T),
            c1_mean = mean(c1, na.rm=T),
            c2_mean = mean(c2, na.rm=T),
            c3_mean = mean(c3, na.rm=T),
            c1_sd = sd(c1, na.rm=T),
            c2_sd = sd(c2, na.rm=T),
            c3_sd = sd(c3, na.rm=T),
            c1_skew = ifelse(length(c1)<=1, NA, skewness(c1, na.rm = T, type = 2)),
            c2_skew = ifelse(length(c2)<=1, NA, skewness(c2, na.rm = T, type = 2)),
            c3_skew = ifelse(length(c3)<=1, NA, skewness(c3, na.rm = T, type = 2))#,
          ) #%>% pivot_wider(names_from, values_from)
          bsts.df2 <- bsts.df %>% full_join(cov.df.wide2, by='t')
          bsts.df2$t <- NULL
          write.csv(bsts.df2, file=bsts.df2.filepath, row.names = F, na = '')
          cat(sprintf('Saved aggregated simulation data to file:\n %s\n',bsts.df2.filepath))
      } else {
          cat(sprintf('Loading data file:\n %s\n',bsts.df2.filepath))
          cov.df.wide2 <- read.csv(bsts.df2.filepath, stringsAsFactors = F)
      }
      
   
      
    }
    
    return(list(
      bsts.df1.filepath=bsts.df1.filepath,
      bsts.df2.filepath=bsts.df2.filepath,
      bsts.df1=bsts.df1,
      bsts.df2=bsts.df2
    ))
      
}

# ## SYNETHIC CONTRL GROUPS FROM COVARIATES CATEGORIES MEAN OUTCOME SERIES
# if (!f3exists) {
#   ## c1 covariates categories
#   c1cats <- cut(simdf$c1, bsts.ctrl.cats)
#   simdf$c1.f <- LETTERS[as.integer(as.factor(c1cats))]
#   ## c2  covariate categories 
#   c2cats <- cut(simdf$c2, bsts.ctrl.cats)
#   simdf$c2.f <- LETTERS[as.integer(as.factor(c2cats))]
#   ##
#   c3cats <- cut(simdf$c3, bsts.ctrl.cats)
#   simdf$c3.f <- LETTERS[as.integer(as.factor(c3cats))]
#   ### SYNTHETIC CONTROL GROUPS
#   .cov.df <- simdf %>%
#     dplyr::filter( 
#       ! is.na(match_id), 
#       group=='control'
#     ) %>%
#     group_by(t, c3.f, c2.f, c1.f) %>%
#     dplyr::summarize( 
#       cov_mean = mean(y, na.rm=T)
#     )  
#   .cov.df$cov_cat.f <- apply(.cov.df[,c('c1.f','c2.f','c3.f')], 1, function(x)paste(x,collapse = ''))
#   .cov.df$c1.f <- NULL
#   .cov.df$c2.f <- NULL
#   .cov.df$c3.f <- NULL 
#   ### HANDLE SPARSE AND EMPTY SERIES (drop if too sparse, fill 'downup' if pct NAs < max.cov.missing)
#   cov.df.wide <- .cov.df %>% 
#     pivot_wider(names_from = cov_cat.f, values_from=c(cov_mean))
#   max.cov.missing <- 0.7
#   cov.cols.keep <- apply(cov.df.wide[,-1], 2, function(x){ 
#      ( ( sum(!is.na(x)) / length(x)  ) > max.cov.missing ) & ## have enough non-missing values
#      ( !is.na(x[1]) | !is.na(x[length(x)]) )    ## has either first or last row non-missing
#   })
#   ## KEEP IF First or last row is not NA (for fill() below) 
#   cov.cols.keep.names <- names(cov.df.wide[,-1])[cov.cols.keep]  ##exclude the 1st column 't'
#   cov.df.wide <- cov.df.wide %>% dplyr::select(all_of(c('t', cov.cols.keep.names)))
#   ##
#   cov.cols.need.fill.bool <- apply(cov.df.wide[,-1], 2, function(x){ 
#     ( sum(!is.na(x)) / length(x)  ) < 1
#   })
#   cov.cols.fill <- names(cov.df.wide)[ cov.cols.need.fill.bool ] 
#   cov.df.wide <- cov.df.wide %>% 
#     ungroup() %>% 
#     tidyr::fill(all_of(cov.cols.fill), .direction = 'downup') 
#   ### FILL REMAINING NAs (after 'downup' fill) with zeros
#   cov.df.wide[is.na(cov.df.wide)] <- 0  
#   ##
#   bsts.df3 <- bsts.df %>% full_join(cov.df.wide, by='t')
#   bsts.df3$t <- NULL
#   write.csv(bsts.df3, file=bsts.df3.filepath, row.names = F, na = '')
# }

##=====================================================================
## ---------SCENARIOS---------------
## LOW DGP SD WEIGHT
dgp.prior.sd.weight.low <- .01
## HIGH DGP SD WEIGHT
dgp.prior.sd.weight.high <- .1
##-----------------------------------
## First we simulate the data for the simulation scenario 1, in which 
## the prior SD is 0.01. 
##
## SIMULATE DATA AND RETURN DATA LIST OBJECT - LOW PRIOR SD
dat1 <- processSimData(simlist, key, effect.type, 
                       dgp.prior.sd.weight.low, 
                       sim.id)
## SIMULATE DATA AND RETURN DATA LIST OBJECT - HIGH PRIOR SD
dat2 <- processSimData(simlist, key, effect.type, 
                       dgp.prior.sd.weight.high, 
                       sim.id)
```


# 1. Bayesian Structural Time Series (BSTS) Introduction

## 1.0. Time Series Data

First load the data simulated from a data generating process with 
a low prior standard deviation weight (`dgp.prior.sd.weight.low=0.01`).
This data set includes the outcome series `y_treatment`, and several 
covariate series from which the BSTS model will select predictors. These
include the lower moments (mean, standard deviation, skewness) of 
three covariates `c1`,`c2`,`c3`.

```{r, message=FALSE}
## load BSTS library
library(bsts)
library(CausalImpact)
library(tibble)
## LOAD FROM FILE
df1 <- read.csv(dat1$bsts.df1.filepath, stringsAsFactors = F) ## don't auto convert chars to factor type
df1 <- as_tibble(df1) ## wrap in a class with extra capabilities
print(df1)
```
We can plot this to visualize the post-intervention change in the 
outcome series `y_treatment`.
```{r outcome_plot, fig.dim = c(6,4), out.width="100%"}
npds <- nrow(df1)
intpd <- round(npds * 0.6)  # time period to split series (60% pre-, 40% post-)
## PLOT
plot(df1$y_treatment, main='Simulated Outcome Time Series (Y)',ylab='Y',xlab='Time')
abline(v=intpd, lty=2)
legend('topleft',legend=c('observed','intervention'), pch=c(1,NA),lty=c(NA,2))
```

## 1.1. State Space Specification - A Simple Baseline Model

Fit a simple BSTS model with only the local level in the state space. 
To visualize the results, we plot the state space components against the 
observed and predicted series. In this cases the state space only has a 
trend component (i.e., the local level, which does not include a slope). 
Following BSTS (and other forecasting) conventions, one-step ahead prediction 
error in the pre-intervention window is used to assess model fit. 
Improved performance of model fit is evident in the decreased error metrics, 
such as the mean absolute error (MAE). 

Create the pre-treatment outcome series `y.pre` to pass into the `bsts()` 
function. Here we replace the post-intervention periods with `NA`'s that 
represent missing values within the `R` language. This is because the 
BSTS model is trained on the pre-intervention outcome (y) data. 
```{r}
## INDICES OF PRE-INTERVENTION and POST-INTERVENTION WINDOWS
pre.idx <- 1:intpd
post.idx <- (intpd+1):npds
## Outcome (response) series
y <- df1$y_treatment
## Train on y pre-treatment but NA's post-treatment
y.pre.treat.NAs.post <- c( y[pre.idx], rep(NA,length(post.idx)) )
## Then use the post-treatment response for causal impact estimation
post.period.response <- y[post.idx]
## Covariates (predictors) - data for the "formula = y ~ predictors" argument
predictors <- df1[ , ! names(df1) %in% 'y_treatment']
# ## Covariates (pred
```
Configure the model's state space by adding state components to the 
state space list `st.sp`. Here `y.pre` is passed into the state space
functions (after the state space list `st.sp`) as the outcome series. 
```{r}
## Initiate empty state space configuration list
st.sp <- list()
## Add local level to trend component of state space
st.sp <- AddLocalLevel(st.sp, y.pre.treat.NAs.post)
## Set BSTS MCMC iterations
bsts.niter <- 1000
```
For the baseline case, scenario 1, we use `df1` for the `predictors` argument
in the `bsts()` function. This `predictors` data table uses `df1`, 
excluding the first column that contains the outcome (`y_treatment`).

## 1.2. BSTS Model Estimation via MCMC

Fit the BSTS model by calling the `bsts()` function to run MCMC estimation 
for `bsts.niter` draws from the stationary distribution of the Markov chain that 
specifies the posterior distribution (assuming convergence was reached,
which will be addressed below.)
```{r}
## Fit BSTS model
bsts.fit <- bsts(y.pre.treat.NAs.post,
                 state.specification = st.sp,
                 niter = bsts.niter)
```
Visualizing the model's behavior can help build  intuition about 
what the model is doing and, ideally, about how to improve its fit to the 
characteristics of your data set. To inspect the contributions of the model 
components, we write a function that will report the model's summary, 
plot the state space components, and if there is a regression in the model, 
it will plot the coefficients and distrubtion of model sizes.
```{r}
###
## Define a function to summarize and visualize the BSTS model components 
###
getBstsSummaryPlots <- function(bsts.fit) {
  par(mfrow=c(1,1)) ## set plotting params to one image in plot window
  print(summary(bsts.fit))
  plot(bsts.fit, 'components')
  if (bsts.fit$has.regression) {
    plot(bsts.fit, 'coefficients')
    plot(bsts.fit, 'size')
    plot(bsts.fit, 'state')
  }
}
## Call our newly defined function
getBstsSummaryPlots(bsts.fit)

```
There appears to be a seasonal component to the time series, which is currently
being captured by the trend. However, this would be a poor model to use as a 
counterfactual because it does not capture how seasonality continues
after the training window. This is visible in the lack of seasonal pattern and
quickly widening forecast intervals in the plot of the trend component 
of the state space after the intervention period (312). 

Then we can plot the contributions to the model's state space against
the observed outcome (black dots) to help with visual understanding of 
this model's prediction (blue line), and later for comparison with 
other models below.
```{r}
# source(file.path(dir_r,'bsts_helper_functions.R'))
plotBstsStateComps(bsts.fit, intpd=intpd, filename=NA) ##NA file does not save
```
This model appears to match the data with the trend only. However, this is only 
accurate for short (e.g., one-step ahead) predictions within the training
window. While the predicted values (blue line) are one-step ahead, in-sample
predictions, the model would lose the seasonal information outside the
training window (post intervention), leaving the counterfactual series
devoid of seasonality when used for causal inference computations (see below).
Therefore, it is crucial to capture seasonality in the outcome time series 
and incorporate it into the BSTS model that will be used as the 
counterfactual for causal inference with the `CasualImpact()` function in
[Section 2](#2. Causal Inference). 


## 1.3. Add Seasonality

To account for seasonality in the time series data generating process, 
we add a seasonal component to the state space ("seasonal.52.1" = one cycle of 
52 periods per year). 
This produces a state contribution of seasonal cycles (e.g., weekly periods each year) 
added to the other state components. The augmented state space then improves 
model performance in terms of the mean absolute error (MAE) of 
one-step ahead predictions during the pre-intervention window. 
```{r}
## Initiate empty state space configuration list
st.sp2 <- list()
## Add local level to trend component of state space
st.sp2 <- AddLocalLevel(st.sp2, y.pre.treat.NAs.post, 
  initial.state.prior = NormalPrior(mu=0, sigma = .01, fixed = FALSE)
)
## Add seasonality to state space (52 weekly periods = 1 yearly cycle) 
st.sp2 <- AddSeasonal(st.sp2, y.pre.treat.NAs.post, 
  nseasons = 52, 
  season.duration = 1, 
  sigma.prior = SdPrior(
    sigma.guess = .01,    ## default guess
    sample.size = .01,    ## default
    upper.limit= Inf ## default
  ), 
  initial.state.prior = NormalPrior(
    mu= 0,   ##default guess
    sigma=0.01  ## default guess
  )
)
## Fit BSTS model: 
bsts.fit2 <- bsts(y.pre.treat.NAs.post ,
                 state.specification = st.sp2, 
                 niter = bsts.niter, ping=0)
## CALL OUR CUSTOM BSTS DIAGNOSTICS SUMMARY
getBstsSummaryPlots(bsts.fit2)
```
Here we have a seasonal component, but it is making a negligible contribution to 
the state space. Meanwhile the trend component still captures the seasonality
pre-intervention and makes only a naive local level forecast post-intervention
That is, the expectation at `t` is the trend at `t-1` plus Gaussian noise.
Since this does not allow us to incorporate the seasonal structure into the 
state space, it would therefore would make a subpar counterfactual for inferring
causal inference as this data set exhibits seasonality. To address this, 
we adjust the Bayesian prior settings for the state space components (which is
a step in machine learning analyses that is commonly referred to as 
hyperparameter tuning). 

## 1.4. Bayesian Priors: Parameter Tuning

We bound outside the scope of this tutorial vignette most of the particulars of
prior elicitation. Beginning at the assumption that the researcher
has theoretical and/or contextual knowledge that can inform  
prior distributions, we focus on illustrating how to adjust the prior 
distribution settings for the `bsts()` function.

```{r}
## Initiate empty state space configuration list
st.sp3 <- list()
## Add local level to trend component of state space
st.sp3 <- AddLocalLevel(st.sp3, y.pre.treat.NAs.post, 
  initial.state.prior = NormalPrior(mu=1, sigma = .01, fixed = FALSE)
)
## Add seasonality to state space (52 weekly periods = 1 yearly cycle) 
y.sd <- sd(y.pre.treat.NAs.post, na.rm = T)
st.sp3 <- AddSeasonal(st.sp3, y.pre.treat.NAs.post, 
  nseasons = 52, 
  season.duration = 1, 
  sigma.prior = SdPrior(
    sigma.guess = y.sd,      ## try empirical y SD
    sample.size = intpd-1,   ## try empirical sample size (pre-intervention)
    upper.limit= 1.5 * y.sd  ## try empirical y SD to set upper limit
  ),
  initial.state.prior = NormalPrior(
    mu= 3,   ## increase initial state prior mu
    sigma=1  ## increase initial state prior sigma
  )
)
## Fit BSTS model:
bsts.fit3 <- bsts(y.pre.treat.NAs.post,
                 state.specification = st.sp3,
                 niter = bsts.niter, ping=0)
## CALL OUR CUSTOM BSTS DIAGNOSTICS SUMMARY
getBstsSummaryPlots(bsts.fit3)
```
```{r}
# source(file.path(dir_r,'bsts_helper_functions.R'))
plotBstsStateComps(bsts.fit3, intpd=intpd, filename=NA) ##NA file does not save
```

## 1.5 Regression

### 1.5.1.  Add Regression `formula` to BSTS function

This uses covariate series in the `predictors` dataframe for the `data` input.
```{r}
## Initiate empty state space configuration list
st.sp4 <- list()
## Add local level to trend component of state space
st.sp4 <- AddLocalLevel(st.sp4, y.pre.treat.NAs.post, 
  initial.state.prior = NormalPrior(mu=0, sigma = .05, fixed = FALSE)
)
## Add seasonality to state space (52 weekly periods = 1 yearly cycle) 
y.sd <- sd(y.pre.treat.NAs.post, na.rm = T)
st.sp4 <- AddSeasonal(st.sp4, y.pre.treat.NAs.post, 
  nseasons = 52, 
  season.duration = 1, 
  sigma.prior = SdPrior(
    sigma.guess = y.sd,      ## use empirical y SD
    sample.size = round(0.5 * (intpd-1)),  ## use half of pre-int window
    upper.limit= 1.5 * y.sd  ## use empirical y SD to set upper limit
  ),
  initial.state.prior = NormalPrior(
    mu= 2,   ## moderate initial state prior mu
    sigma=0.5  ## moderate initial state prior sigma
  )
)
## Fit BSTS model: formula “y.pre ~ .” indicates inclusion of regression  
## component (all covariates in df1[,-1] dataframe)
bsts.fit4 <- bsts(y.pre.treat.NAs.post ~ . ,
                 state.specification = st.sp4,
                 data = predictors,  ## -1 excludes the outcome in 1st column 
                 niter = bsts.niter)
## CALL OUR CUSTOM BSTS DIAGNOSTICS SUMMARY
getBstsSummaryPlots(bsts.fit4)
```

```{r}
plotBstsStateComps(bsts.fit4)
```

### 1.5.2.  Variable Selection: Spike-and-Slab Priors

Variable selection is a crucial step in building a counterfactual time series
that sufficiently approximates (i.e., correlates to a sufficient degree with) 
the outcomes series in the pre-intervention window. 

In Bayesian structural time series models, variable selection is 
incorporated into the model within a Bayesian framework via 
spike-and-slab priors. 

There are three ways to modify the the number of covariate series included
in the BSTS model, which is also referred to as the "model size," or 
size of the regression component of the model. 

1. Pass `expected.model.size` argument into `bsts()` directly
2. Create a `SpikeSlabPrior` object to pass into `bsts()` by:
 - 2a. Using `expected.model.size` argument of `SpikeSlabPrior()`
 - 2b. Specifying inclusion probability for each covariate in `SpikeSlabPrior()`

First, the simplest method is to set the `expected.model.size` attribute 
(of the `SpikeSlabPrior()`) by passing the `expected.model.size` argument 
into the `bsts()` function directly.
```{r}
##TODO
st.sp5 <- st.sp4
# #=================
# # Option 1. Specify expected model size (internally creates SpikeSlabPrior)
# #----------------
# #   This uniformly sets prior (spike) probabilities = (1 / expected.model.size)
# bsts.fit5 <- bsts(y.pre ~ .,
#                state.specification = st.sp5,
#                niter = bsts.niter,
#                data = initial.claims,
#                expected.model.size = 5,  ## argument passed to SpikeSlabPrior
#                seed = 7531, ping=0)  

```

Second, you can create a `SpikeSlabPrior` object to pass into the `bsts()`
function. 

One way to do this is by using `expected.model.size` argument 
of `SpikeSlabPrior()`. This allows you to set the expected model size in a 
simple manner when all covariates are assumed to have equal naive inclusion
probabilities. This is just like the first method above but the intermediate
step of creating a `SpikeSlabPrior` object enables the researcher to adjust 
the expected model size and all other regression prior parameter settings 
in the same step. 
```{r}
##TODO
st.sp6 <- st.sp5
# #=================
# # Option 2. Create SpikeSlabPrior object and pass it into BSTS function
# #-----------------
# ##----------------
# #  2A. Set expected.model.size in SpikeSlabPrior (with other options)
# priorObjA <- SpikeSlabPrior(x = model.matrix(y ~ ., data=data), 
#                             y = y, 
#                             expected.model.r2 = .5,
#                             prior.df = 0.01,
#                             expected.model.size = 5, ## argument set directly in SpikeSlabPrior
#                             prior.information.weight = 10) ## in terms of observation count
#          
# # Run the bsts model with the SpikeSlabPrior object ‘priorObjA’
# bsts.fit6 <- bsts(y ~ ., state.specification = st.sp, 
#                 data = initial.claims, 
#                 niter = bsts.niter, 
#                 prior= priorObjA, 
#                 seed = 7531)

```

Finally, the other way to create a `SpikeSlabPrior` object to pass
into the `bsts()`function is by specifying prior inclusion probabilities
(and estimates) for each covariates series in `predictors`. This is useful
when the researcher has prior knowledge that certain covariates are 
more likley to be important contributors to the counterfactual series
and should therefore be included in the model in more iterations 
(i.e., more MCMC draws from the posterior predictive distribution). 

```{r}
st.sp7 <- st.sp6
##TODO
# ##----------------
# # 2B. Specify prior.inclusion.probabilities for each covariate 
# #   where length of prior spikes and means vectors should equal the number of 
##    covariates
# #   (i.e., this example with vector lengths = 11 implies 
##      ‘data’ has 11 columns) 
# prior.spikes <- c(0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,1,0.1)
# prior.means <- c(0,0,0,0,0,0,0,0,0,0.6,0)
# 
# # Directly set prior spike probabilities for each covariate in the prior object
# priorObjB <- SpikeSlabPrior(x = model.matrix(y ~ ., data=data), 
#                             y = y, 
#                             expected.model.r2 = .5,
#                             prior.df = 0.01,
#                             prior.information.weight = 10, ##  ~ obs. count
#                             prior.inclusion.probabilities = prior.spikes, 
#                             optional.coefficient.estimate = prior.means)
#  
# # Run the bsts model with the SpikeSlabPrior object ‘priorObjB’
# bsts.fit7 <- bsts(y ~ ., state.specification = st.sp, 
#                 data = initial.claims, 
#                 niter = bsts.niter, 
#                 prior= priorObjB, 
#                 seed = 7531)

```


## 1.6. Compare State Space Configurations 

Besides the default state space containing only a local level component, 
we can evaluate different state space configurations, such as those
including a local linear trend and semi-local linear trend.

### 1.6.0. Local Level

This was the simple model already introduced above. As a state space without
a linear trend, this model will serve as a baseline for comparison 
with other state space configurations that contain a type of linear trend. 

### 1.6.1. Local linear trend 

The local linear trend is useful for short term predictions of relatively 
well-behaved time series. 
```{r}
## Initiate empty state space configuration list
st.sp8 <- list()
## Add local level to trend component of state space
st.sp8 <- AddLocalLinearTrend(st.sp8, y.pre.treat.NAs.post, 
  level.sigma.prior=SdPrior(sigma.guess=.01, sample.size=32, fixed = F, upper.limit = 1.2), 
  slope.sigma.prior=SdPrior(sigma.guess=.01, sample.size=.01, fixed = F, upper.limit = 1.2), 
  initial.level.prior=NormalPrior(mu=0, sigma=.01, fixed = F), 
  initial.slope.prior=NormalPrior(mu=0, sigma=.01, fixed = F)
)
## Add trigonometric seasonality to state space
st.sp8 <- AddSeasonal(st.sp8, y.pre.treat.NAs.post, 
  nseasons = 52, 
  season.duration = 1, 
  sigma.prior = SdPrior(
    sigma.guess = 0.01,    ## guess
    sample.size = 0.01,    ## default
    upper.limit= 1.2 ##1.5 * sd(y, na.rm = T)
  ), 
  initial.state.prior = NormalPrior(
    mu= 0,   ##guess
    sigma=0.01,  ## guess
    initial.value=0  ## default to mu
  )
)


## Fit BSTS model: formula “y.pre ~ .” indicates inclusion of regression  
## component (all covariates in df1[,-1] dataframe)
bsts.fit8 <- bsts(y.pre.treat.NAs.post ~ . ,
                 state.specification = st.sp8,
                 data = predictors,  ## -1 excludes the outcome in 1st column 
                 niter = bsts.niter)

## CALL OUR CUSTOM BSTS SUMMARY
getBstsSummaryPlots(bsts.fit8)
plotBstsStateComps(bsts.fit8)
```

### 1.6.2. Semilocal linear trend 

The semilocal linear trend component in the BSTS model state space is 
useful for longer-term forecasts wherein the linear trend persists longer, 
so tighter prediction bounds are reasonable over longer post-intervention 
window. 
```{r, fig.width="100%", }
## Initiate empty state space configuration list
st.sp9 <- list()
## Add local level to trend component of state space
st.sp9 <- AddSemilocalLinearTrend(st.sp9, y.pre.treat.NAs.post, 
  level.sigma.prior=SdPrior(sigma.guess=.01, sample.size=32, initial.value=.01),
  slope.mean.prior=NormalPrior(mu = 0, sigma = .01, initial.value = 0), 
  slope.ar1.prior=Ar1CoefficientPrior(mu = 0, 
                                      sigma = .01, 
                                      force.stationary = FALSE, 
                                      force.positive = FALSE, 
                                      initial.value = 0
                                      ),
  slope.sigma.prior=SdPrior(sigma.guess=.01, sample.size=32, initial.value=.01),
  initial.level.prior=NormalPrior(mu = 0, sigma = .01, initial.value = 0),
  initial.slope.prior=NormalPrior(mu = 0, sigma = .01, initial.value = 0)
)
## Add trigonometric seasonality to state space
st.sp9 <- AddSeasonal(st.sp9, y.pre.treat.NAs.post, 
  nseasons = 52, 
  season.duration = 1, 
  sigma.prior = SdPrior(
    sigma.guess = 0.01,    ## guess
    sample.size = 2,    ## default
    upper.limit= 1.5 * sd(y, na.rm = T)
  ), 
  initial.state.prior = NormalPrior(
    mu= 0,   ##guess
    sigma=0.01,  ## guess
    initial.value=0  ## default to mu
  )
)


## Fit BSTS model: formula “y.pre ~ .” indicates inclusion of regression  
## component (all covariates in df1[,-1] dataframe)
bsts.fit9 <- bsts(y.pre.treat.NAs.post ~ . ,
                 state.specification = st.sp9,
                 data = predictors,  ## -1 excludes the outcome in 1st column 
                 niter = bsts.niter)

## CALL OUR CUSTOM BSTS DIAGNOSTICS SUMMARY
getBstsSummaryPlots(bsts.fit9)
```

```{r}
# reslist <- list()
# ## SD LOW SCENARIO KEY
# scenario_key <- '1_noCtrl_lowSd'
# reslist[[scenario_key]] <- list(
#   level=bsts.fit, 
#   seasonal=bsts.fit2, 
#   localLinearTrend=bsts.fit3,
#   SemilocalLinearTrend=bsts.fit4
# )
# CompareBstsModels(reslist[[scenario_key]])
# 
# sum(abs(bsts.fit$one.step.prediction.errors[200:1000]))
# sum(abs(bsts.fit2$one.step.prediction.errors[200:1000]))
# sum(abs(bsts.fit3$one.step.prediction.errors[200:1000]))
# sum(abs(bsts.fit4$one.step.prediction.errors[200:1000]))
```

## 1.7. Check MCMC Convergence and Model Diagnostics

To inspect the model's state space component contributions and check 
```{r}
###
## Define a funciton to call all of our plotting, 
##    diagnostics and converngence checks functions
###
getBstsDiagnosticPlots <- function(bsts.fit) {
  par(mfrow=c(1,1))
  checks <- bstsPostPredChecks(bsts.fit, save.plot = F, return.val = T)
  cat('MCMC Convergence Diagnostics:\n')
  cat(checks$summary)
}

getBstsDiagnosticPlots(bsts.fit9)
```

Draws from the posterior distribution of the stationary Markov chain(s)
are used to estimate the model prediction at each time period though 
Markov chain Monte Carlo (MCMC) estimation. However, when the Markov chains
have not yet converged (usually due to insufficient MCMC burn-in period
or sampled iterations), then the iterations cannot be treated as draws from
the stationary distribution for the posterior predicted distribution. Thus, the 
estimates may be unstable and/or biased, so users must assess convergence of 
the MCMC chains. Similarly, there is need to assess how the model fits the 
observed data. 

For this purpose we plot MCMC convergence and model fit checks for the outcome 
(Y, top row panels) and the standardized residuals (bottom row panels). 

We Begin with the simple model containing only a local level `bsts.fit`.
```{r mcmc_diag_fit, fig.dim = c(14, 10), out.width="100%", include=FALSE}
getBstsSummaryPlots(bsts.fit)
getBstsDiagnosticPlots(bsts.fit)
```
In the first column, the trace of the Markov chain (mean of draws per period) 
is shown for the posterior predictive distribution of the outcome (Y). 
For model fit, the observed and predicted values of Y are compared (top-center), 
where tighter alignment indicates better fit. Additionally, using the maximum 
value of Y as an auxiliary statistic, the Bayesian p-val presents the proportion of
maximum Y values (from MCMC) that are larger than the observed largest 
value of Y. Smaller values of Bayesian p-val indicate worse fit, which offers a 
similar in interpretation to the frequentist null hypothesis statistical test 
(NHST) under a null assumption of a well fitting model. 
Values of Bayesian p-val >= alpha (conventionally 0.05) would therefore not reject the 
null of good fit, whereas Bayesian p-val < alpha indicates problem(s) of fit to 
be addressed (e.g., by increasing MCMC iterations, or respecifying the state space).

Next we compare these diagnostics with the model containing seasonality,
`bsts.fit2`.
```{r mcmc_diag_fit2, fig.dim = c(14, 10), out.width="100%", include=FALSE}
ppcheck2 <- bstsPostPredChecks(bsts.fit2, save.plot=F, return.val = T)
```

With all checks ow we have a BSTS model to serve as the counterfactual for causal inference.


# 2. Causal Inference

The preferred fitted bsts model `bsts.fit4` (i.e., the model with the least 
pre-intervention, one-step-ahead cumulative absolute prediction error) 
can now be passed into the `CausalImpact()`function. 
This will use `bsts.fit4`, which was fitted on the pre-intervention 
data, in order to forecast (i.e., predict outside of the pre-intervention
sample time window) the counterfactual series (i.e., the hypothetical 
outcome series if there had been no exposure to treatment).  
The pointwise causal impact of the intervention is then computed as the 
difference between the predicted (counterfactual untreated outcome) and 
observed (actual treated outcome). The cumulative impact estimate is the 
cumulative sum of the pointwise impact estimates. 

```{r}
# ## Post period response
# y.post <- df1$y_treatment
# y.post[1:(intpd-1)] <- NA  ## SETTING values before intervention to missing
## Causal impact estimation: fitted BSTS model forecasts the counterfactual
impact.amount <- CausalImpact(bsts.model = bsts.fit4,
                              post.period.response = post.period.response,
                              alpha=0.05, model.args=list(niter = bsts.niter))

```
Echo the summary of causal inference results based on the model `bsts.fit`
and plot the causal impact figures (original, pointwise, cumulative).
```{r}
summary(impact.amount)
plot(impact.amount)
```


# 3. Covariate Series and Regression Performance
<!-- # 3. Control Group Series (Quasi-Experimental Design in Regression Component) -->

```{r}

```



# 4. Dynamic Causal Inference: MCC Curve Shapes

```{r}

```



# 5. Sensitivity Analyses


## 5.1. BSTS Prior SD Settings

```{r}

```


## 5.2. Regression Features

### 5.2.1. Model Size (model selects how many candidate series in counterfactual)

```{r}
## checking default, others (1,4,7)
```


### 5.2.2.  Expected R^2^ (how much outcome does the model explain)

```{r}
## check default, plus high, plus low
```


### 5.2.3. ##???### Candidate Predictors (series from which the model selects)

Including covariates that have more or less information (correlation)
with the outcome series enable the model to create a better (or worse)
counterfactual, from which causal impact is then estimated. 

if the well-behaving series has the same unit of analysis as the outcome, 
then DiD uses this as control group (counterfactual)

- bsts does not need to be parallel trend; did requires parallel trend 
(refer to paper)

```{r}
## Show predictor series and some measure, like correlation
```










Save simulation list to serialized data file

```{r}
reslist.filepath <- file.path(dir_proj,
                              sprintf('__bsts_vignette_1_sim_RESLIST_%s_%s.rds',
                                   effect.type, sim.id))
saveRDS(reslist, file = reslist.filepath)
```


This concludes the BSTS tutorial vignette. 



